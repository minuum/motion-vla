# Motion VLA í”„ë¡œì íŠ¸ ë¸Œë¦¬í•‘ (2026-01-02)

## ğŸ“Š í”„ë¡œì íŠ¸ í˜„í™© ìš”ì•½

### ì™„ë£Œëœ ì‘ì—…
1. âœ… **ê¸°ìˆ  ìŠ¤íƒ êµ¬í˜„** (4ê°œ Core Component)
   - VisionLanguageEncoder (PaliGemma/OpenVLA)
   - FlowActionExpert (Ï€0-style flow-matching)
   - ResidualCorrectionHead (IRP ê¸°ë°˜)
   - StyleController (Adverb ë§¤í•‘)

2. âœ… **í•˜ë“œì›¨ì–´ ì„ ì • ë° ìŠ¤í™ ì¡°ì‚¬**
   - Dobot E6 Magician (6ì¶•, 450mm reach, 0.75kg payload)
   - ROS2 Humble ì§€ì› í™•ì¸
   - Action space ì •ì˜ (7-dim)

3. âœ… **Task ì„ ì • Framework ìˆ˜ë¦½**
   - 5ê°€ì§€ ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ ì²´ê³„ì  ë¶„ë¥˜
   - Dobot E6 ì œì•½ ì¡°ê±´ ë°˜ì˜
   - ìµœì¢… 4ê°œ Task Suite ì„ ì •

---

## ğŸ¯ í•µì‹¬ ì—°êµ¬ ë°©í–¥: "Motion-Aware VLA"

### ì°¨ë³„í™” í¬ì¸íŠ¸
ê¸°ì¡´ VLA (RT-2, OpenVLA)ëŠ” **"What"(ë¬´ì—‡ì„)ê³¼ "Where"(ì–´ë””ì—)**ë§Œ ë‹¤ë£¸.  
ìš°ë¦¬ëŠ” **"How"(ì–´ë–»ê²Œ) + "Correction"(ì‹¤ì‹œê°„ ìˆ˜ì •)**ì„ ì¶”ê°€í•˜ì—¬ **Motion-Aware VLA** êµ¬ì¶•.

### í•™ìˆ ì  ê¸°ì—¬
1. **Adverb-Conditioned Control**: ë¶€ì‚¬ë¡œ ëª¨ì…˜ ìŠ¤íƒ€ì¼ ì œì–´ (carefully, quickly ë“±)
2. **Real-time Language Correction**: ë™ì‘ ì¤‘ ì–¸ì–´ í”¼ë“œë°±ìœ¼ë¡œ ê¶¤ì  ìˆ˜ì •
3. **Small-scale Robot VLA**: ì‚°ì—…ìš© ëŒ€í˜• ë¡œë´‡ì´ ì•„ë‹Œ Desktop robotì—ì„œ ê²€ì¦

---

## ğŸ“‹ ìµœì¢… ì„ ì • Task Suite (ìš°ì„ ìˆœìœ„)

### Task 1: Pick & Place with Adverb Control (P0)
**ëª©í‘œ**: ì–¸ì–´ ì§€ì‹œë¡œ ë¬¼ì²´ë¥¼ ì§‘ì–´ ë°°ì¹˜í•˜ë˜, ë¶€ì‚¬ë¡œ ì†ë„/ìŠ¤íƒ€ì¼ ì œì–´

**ì˜ˆì‹œ Instructions**:
- "Pick up the red cup **carefully**" â†’ ì†ë„ 0.25 m/s
- "Place it on the left **quickly**" â†’ ì†ë„ 0.5 m/s
- "Move the blue block **steadily**" â†’ Jerk ìµœì†Œí™”

**ë°ì´í„° ì¡°í•©**: 3,600ê°€ì§€ (ì‹¤ì œ ìˆ˜ì§‘ 250 episodes)
- ë¬¼ì²´ 4ì¢… x ìƒ‰ìƒ 4ê°€ì§€ x ìœ„ì¹˜ 25 x ëª©í‘œ 3 x ë¶€ì‚¬ 3

**êµ¬í˜„ ë‚œì´ë„**: â­â­â­ (ì¤‘ê°„)
**ì—°êµ¬ ê¸°ì—¬ë„**: â­â­â­â­ (ë†’ìŒ, Workshop ë…¼ë¬¸ ê°€ëŠ¥)

---

### Task 2: Push with Adverb (P0-ì˜ˆë¹„)
**ëª©í‘œ**: Task 1ê³¼ ë™ì¼í•˜ì§€ë§Œ "Push" ìŠ¤í‚¬ ì¶”ê°€

**ì´ìœ **: 
- Pick & Placeë§Œìœ¼ë¡œëŠ” ìŠ¤í‚¬ ë‹¤ì–‘ì„± ë¶€ì¡±
- PushëŠ” êµ¬í˜„ ì‰¬ìš°ë©´ì„œ ìƒˆë¡œìš´ interaction íŒ¨í„´ ê²€ì¦

**ë°ì´í„° ì¡°í•©**: ~200ê°€ì§€
**ë‚œì´ë„**: â­â­ (ì‰¬ì›€)

---

### Task 3: Real-time Language Correction (P1)
**ëª©í‘œ**: ë¡œë´‡ ë™ì‘ ì¤‘ "Move right", "Slower" ê°™ì€ í”¼ë“œë°±ìœ¼ë¡œ ê¶¤ì  ì¦‰ì‹œ ìˆ˜ì •

**Correction Commands**:
| ëª…ë ¹ | Delta Action |
|:---|:---|
| "Move right" | dx = +0.05m |
| "Higher" | dz = +0.05m |
| "Slower" | velocity Ã— 0.5 |

**ë°ì´í„° ì¡°í•©**: 108ê°€ì§€ (ì‹¤ì œ ìˆ˜ì§‘ 100 episodes)
**ë‚œì´ë„**: â­â­â­â­ (ì–´ë ¤ì›€, ì‚¬ëŒ ì°¸ì—¬ í•„ìˆ˜)
**ì—°êµ¬ ê¸°ì—¬ë„**: â­â­â­â­â­ (ë§¤ìš° ë†’ìŒ, Top Conference ê°€ëŠ¥)

**âš ï¸ ë¦¬ìŠ¤í¬**: Human-in-the-loop ë°ì´í„° ìˆ˜ì§‘ ë³‘ëª©

---

### Task 4: Stack Blocks (P2)
**ëª©í‘œ**: ê²€ì¦ìš© ì¶”ê°€ íƒœìŠ¤í¬, "Stack 3 blocks **carefully**"

**ì´ìœ **: Generalization ê²€ì¦, ìƒˆë¡œìš´ ìŠ¤í‚¬ ì¡°í•©

---

## ğŸ—‚ï¸ ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ ì„ ì • ê·¼ê±°

### Category 1: ì¡°ì‘ ìŠ¤í‚¬
- âœ… **ì±„íƒ**: Pick, Place, Push (Dobot E6 ì í•©)
- âš ï¸ **ë³´ë¥˜**: Pour, Insert (ì„¼ì„œ/ì •ë°€ë„ ë¶€ì¡±)
- ğŸ“ **í›„ë³´**: Stack, Slide

### Category 2: ì–¸ì–´ ì œì–´ ì°¨ì›
- â­â­â­â­â­ **How (Adverb)**: ì°¸ì‹ ì„± ìµœê³ 
- â­â­â­â­â­ **Correction**: HRI ê°€ì¹˜ ë†’ìŒ
- â­â­ **When (íƒ€ì´ë°)**: ì„¼ì„œ ë¶€ì¡±ìœ¼ë¡œ ì œì™¸

### Category 3: ë¬¼ì²´ ì†ì„±
- âœ… Rigid objects (Cube, Sphere, Cylinder)
- âœ… 4ê°€ì§€ ìƒ‰ìƒ (Red, Blue, Green, Yellow)
- âœ… 2ê°€ì§€ í¬ê¸° (Small 5cm, Medium 10cm)
- âŒ Deformable (Sim2Real ì–´ë ¤ì›€)

### Category 4: ë‚œì´ë„
- **L2 (Medium)**: Pick & Place â†’ 80-90% ì„±ê³µë¥ 
- **L3 (Hard)**: Adverb Control â†’ 70-85%
- **L4 (Very Hard)**: Correction â†’ 60-75%

### Category 5: í‰ê°€ ë©”íŠ¸ë¦­
1. Success Rate (í•„ìˆ˜)
2. Execution Time (Adverb ê²€ì¦)
3. Collision Count (ì•ˆì „ì„±)
4. Correction Latency (ë°˜ì‘ì„±)

---

## ğŸ“Š ë°ì´í„° ìš”êµ¬ëŸ‰ ì´ì •ë¦¬

| Task | Isaac Sim | Real Teleoperation | Human-in-the-loop | í•©ê³„ |
|:---|:---:|:---:|:---:|:---:|
| Task 1 (Pick & Place + Adverb) | 200 | 50 | 0 | 250 |
| Task 2 (Push) | 100 | 20 | 0 | 120 |
| Task 3 (Correction) | 0 | 0 | 100 | 100 |
| Task 4 (Stack) | 100 | 20 | 0 | 120 |
| **ì´ê³„** | 400 | 90 | 100 | **590 episodes** |

### ì˜ˆìƒ ì†Œìš” ì‹œê°„
- Sim ìë™ ìƒì„±: 400 x 2ë¶„ = **13.3ì‹œê°„**
- Real Teleoperation: 90 x 5ë¶„ = **7.5ì‹œê°„**
- Human Correction: 100 x 3ë¶„ = **5ì‹œê°„**
- **ì´ê³„**: ~26ì‹œê°„ (ì‹¤ì œ 50ì‹œê°„ ì˜ˆìƒ, ë””ë²„ê¹… í¬í•¨)

---

## ğŸš€ êµ¬í˜„ ì „ëµ (2ë‹¨ê³„)

### Phase 1 (Week 1-4): Task 1 + Task 2
**ëª©í‘œ**: Pick & Place + Push with Adverb Control

**ì´ìœ **:
- ë‘˜ ë‹¤ Isaac Sim ë°ì´í„°ë¡œ í•™ìŠµ ê°€ëŠ¥
- ë¹ ë¥¸ ì„±ê³¼ ë„ì¶œ (Workshop ë…¼ë¬¸)

**Deliverable**: 
- 4-6 page Workshop paper
- Live demo video

---

### Phase 2 (Week 5-8): Task 3 ì¶”ê°€
**ëª©í‘œ**: Real-time Correction ê¸°ëŠ¥ í†µí•©

**ì´ìœ **:
- ì°¸ì‹ ì„± ìµœê³  (Top Conference ê°€ëŠ¥)
- í•˜ì§€ë§Œ ë°ì´í„° ìˆ˜ì§‘ ì–´ë ¤ì›€

**Deliverable**:
- 8 page Full Conference paper (CoRL, ICRA, IROS ëª©í‘œ)

---

## âš ï¸ ì£¼ìš” ë¦¬ìŠ¤í¬ ë° ëŒ€ì‘

| ë¦¬ìŠ¤í¬ | í™•ë¥  | ì˜í–¥ë„ | ëŒ€ì‘ ë°©ì•ˆ |
|:---|:---:|:---:|:---|
| **Sim2Real Gap** | ë†’ìŒ | ë†’ìŒ | Domain randomization ê°•í™” |
| **Real Robot ì ‘ê·¼ì„±** | ì¤‘ê°„ | ë†’ìŒ | Dobot E6 ì‚¬ìš© ìŠ¤ì¼€ì¤„ ì‚¬ì „ í™•ë³´ |
| **Human ì°¸ì—¬ì ëª¨ì§‘** | ì¤‘ê°„ | ì¤‘ê°„ | Task 3ëŠ” Phase 2ë¡œ ì—°ê¸° |
| **í•™ìŠµ ë¶ˆì•ˆì •** | ë‚®ìŒ | ì¤‘ê°„ | Pre-trained VLM í™œìš© |

---

## ğŸ“š ê´€ë ¨ ë¬¸ì„œ
- `docs/dobot_e6_specs.md`: ë¡œë´‡ ìƒì„¸ ìŠ¤í™
- `docs/implementation_plan.md`: 8ì£¼ êµ¬í˜„ ë¡œë“œë§µ
- `docs/task_evaluation.md`: Task í‰ê°€ ìƒì„¸ ë¶„ì„
- `docs/architecture.md`: ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

---

## ğŸ“ ë…¼ë¬¸ ì¶œíŒ ì „ëµ

### Option A (ì•ˆì „): Workshop ë…¼ë¬¸
- **Target**: NeurIPS/ICML Workshop, CoRL Workshop
- **Content**: Task 1 + Task 2 (Pick, Place, Push with Adverb)
- **Timeline**: Week 4 ì™„ë£Œ â†’ 5ì›” ì œì¶œ

### Option B (ë„ì „): Main Conference
- **Target**: CoRL 2026, ICRA 2027, IROS 2026
- **Content**: Task 1 + 2 + 3 (Correction í¬í•¨)
- **Timeline**: Week 8 ì™„ë£Œ â†’ 9ì›” ì œì¶œ

**ê¶Œì¥**: Option A ë¨¼ì € ì§„í–‰ â†’ ì„±ê³µ ì‹œ Option B í™•ì¥

---

## ë‹¤ìŒ ë‹¨ê³„ (ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥)

1. **Isaac Sim í™˜ê²½ êµ¬ì¶• í˜‘ì—…**
   - Dobot E6 URDF import
   - ì‘ì—… í…Œì´ë¸” ì„¤ì • (800x600mm)
   
2. **ë°ì´í„° ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±**
   - `scripts/generate_sim_data.py`
   - `scripts/collect_real_demos.py`

3. **End-to-End Pipeline í†µí•©**
   - 4ê°œ Componentë¥¼ `MotionVLAPipeline` í´ë˜ìŠ¤ë¡œ í†µí•©
   - Dummy data ê²€ì¦


---


# Dobot E6 Magician Specifications

> **Reference**: Official DOBOT documentation and vendor specifications  
> **Last Updated**: 2026-01-02

## Hardware Specifications

### Physical Dimensions
- **Model**: DOBOT Magician E6 (6-Axis Collaborative Robot)
- **Weight**: â‰¤7.2 kg
- **Base Dimensions**: 162mm x 120mm x 103mm
- **Working Radius**: 450mm
- **Repeatability**: Â±0.1mm

### Performance
- **Degrees of Freedom**: 6-axis
- **Payload Capacity**: 0.75kg (750g)
- **Maximum TCP Speed**: 0.5 m/s
- **Maximum Joint Speed**: 120Â°/s

### Power & Electronics
- **Input Power**: 100V~240V AC, 50/60 Hz
- **Rated Voltage**: 48V DC, 5A
- **Power Consumption**: 130W
- **IP Rating**: IP20

---

## Control Interfaces

### Communication
- **Primary**: TCP/IP (Ethernet)
- **Protocol**: Modbus TCP
- **Ports**: 2x Ethernet ports

### I/O Interface
**Arm Tip**:
- 2x Digital Inputs (DI)
- 2x Digital Outputs (DO)
- 1x 24V
- 1x GND

**Base**:
- 16x Digital Inputs (DI)
- 16x Digital Outputs (DO)
- 4x 24V
- 4x GND
- I/O Power: 24V, max 2A (0.5A per channel)

### External Interfaces
- 1x Emergency Stop (EMO)
- 1x ABZ Encoder
- 1x Power Connector

---

## Software & Programming

### Official Software
- **Control Software**: DobotStudio Pro
- **Supported OS**: Ubuntu 22.04 (for ROS2)

### Programming Support
- **ROS/ROS2**: ROS2 Humble (Official SDK available)
- **Languages**: Python, C++, C#, MATLAB, LabVIEW, Kotlin
- **Graphical Programming**: Scratch-type block programming
- **Lua Scripting**: Via DobotStudio Pro

### Special Features
- **Drag-to-Teach**: Proprietary trajectory replay technology
- **Collision Detection**: Built-in safety feature
- **Status Indicator**: LED ring for operational monitoring

---

## Action Space for VLA

### Joint Space
```python
# 6 revolute joints
joint_limits = {
    "joint_1": [-135, 135],   # degrees
    "joint_2": [-5, 85],
    "joint_3": [-10, 95],
    "joint_4": [-180, 180],
    "joint_5": [-90, 90],
    "joint_6": [-180, 180],
}
```

### Cartesian Space (TCP)
```python
# End-effector pose
tcp_workspace = {
    "x": [-450, 450],      # mm (working radius)
    "y": [-450, 450],
    "z": [0, 450],         # height above base
    "roll": [-180, 180],   # degrees
    "pitch": [-180, 180],
    "yaw": [-180, 180],
}
```

### Gripper
- **Type**: Pneumatic or servo gripper (optional end-effector)
- **Control**: Binary (open/close) or position control
- **Action Representation**: `gripper âˆˆ [0, 1]` (0=open, 1=closed)

---

## Operating Environment

### Physical Environment
- **Temperature**: 0Â°C to 40Â°C
- **Humidity**: 25% to 85% (non-condensing)
- **Workspace**: Desktop-sized (recommended 1m x 1m area)

### Safety Features
- Collision detection with automatic stop
- Emergency stop button
- Streamlined body design (reduce collision risk)
- LED status indicator (green=normal, red=error)

---

## VLA Integration Considerations

### Strengths for VLA Research
âœ… **High Repeatability** (Â±0.1mm): Consistent baseline for learning  
âœ… **ROS2 Native Support**: Easy integration with our pipeline  
âœ… **Drag-to-Teach**: Efficient human demonstration collection  
âœ… **Desktop Size**: Accessible for lab experiments  
âœ… **TCP/IP Control**: Low-latency command transmission

### Limitations
âš ï¸ **Payload** (0.75kg): Cannot handle heavy objects  
âš ï¸ **Speed** (0.5 m/s max): Limited dynamic task capability  
âš ï¸ **Reach** (450mm): Small workspace compared to industrial robots  
âš ï¸ **No Force/Torque Sensor**: Cannot perform force-sensitive tasks  

### Recommended Task Types
1. **Light Object Manipulation**: Blocks, cups, small tools (< 500g)
2. **Precision Tasks**: Assembly, pick-and-place with tight tolerances
3. **Vision-based Tasks**: Color/shape recognition, sorting
4. **Language-conditioned Control**: Speed/style variations within safe limits

---

## ROS2 Integration

### Available ROS2 Packages
- **dobot_ros2**: Official ROS2 driver
- **moveit2_dobot**: MoveIt2 integration for motion planning
- **dobot_description**: URDF model for simulation

### Topic Structure (ì˜ˆìƒ)
```bash
# Control
/dobot/joint_command        # JointTrajectory
/dobot/gripper_command      # GripperCommand

# Feedback
/dobot/joint_states         # JointState
/dobot/tcp_pose            # PoseStamped
/dobot/collision_status    # Bool

# Camera (if equipped)
/dobot/camera/image_raw    # Image (RGB)
```

---

## References
- [Official Dobot Website](https://www.dobot.cc/)
- [ROS2 Dobot SDK (GitHub)](https://github.com/Dobot-Arm/...)
- Vendor Specifications: Scan.co.uk, RobotShop, Unchained Robotics


---


# Ï€0 vs ê¸°ì¡´ VLA ë¹„êµ ë¶„ì„ ë° íƒœìŠ¤í¬ ì¬ì •ì˜

> **ì‘ì„±ì¼**: 2026-01-02  
> **ëª©ì **: Ï€0ì˜ ì‹¤ì œ ì ìš© ì‚¬ë¡€ ë¶„ì„ â†’ ìš°ë¦¬ í”„ë¡œì íŠ¸ì— ìµœì í™”ëœ íƒœìŠ¤í¬ ì„ ì •

---

## 1. Ï€0ê°€ ì„ íƒí•œ Taskì™€ ê·¸ ì´ìœ 

### Ï€0ì˜ ëŒ€í‘œ Task
| Task | ì„¤ëª… | ì™œ ì„ íƒë˜ì—ˆëŠ”ê°€ |
|:---|:---|:---|
| **Laundry Folding** | ë¹¨ë˜ ê°œê¸° | **Deformable object** ì¡°ì‘ì˜ ê·¹í•œ, ë¬´í•œí•œ ì´ˆê¸° ìƒíƒœ â†’ ì¼ë°˜í™” ëŠ¥ë ¥ ê²€ì¦ |
| **Table Bussing** | ì‹íƒ ì¹˜ìš°ê¸° | **Emergent strategy** (ì ‘ì‹œ í„¸ê¸°, ë¶„ë¥˜), Multi-object handling |
| **Grocery Bagging** | ì¥ë³´ê¸° ë´‰íˆ¬ ë‹´ê¸° | ë‹¤ì–‘í•œ ë¬¼ì²´ í¬ê¸°/ë¬´ê²Œ, **Sequencing** ëŠ¥ë ¥ ê²€ì¦ |
| **Box Assembly** | ìƒì ì¡°ë¦½ | Multi-step, **ì •ë°€ ì¡°ì‘** ìš”êµ¬ |

### ì„ íƒ ê¸°ì¤€ (Physical Intelligenceì˜ ì² í•™)
1. **ë³µì¡ë„ (Complexity)**: ë‹¨ìˆœ ë°˜ë³µ ë¶ˆê°€, ìƒí™© íŒë‹¨ í•„ìš”
2. **ì†ì¬ì£¼ (Dexterity)**: ë¯¸ì„¸í•œ í˜ ì¡°ì ˆ, ê³ ì£¼íŒŒ ì œì–´
3. **ì¼ë°˜ì„± (Generalization)**: íŠ¹ì • ë¬¼ì²´ê°€ ì•„ë‹Œ "ì˜·", "ì ‘ì‹œ" ê°™ì€ ì¹´í…Œê³ ë¦¬ ì „ì²´
4. **ì‹¤ìš©ì„± (Relatability)**: ì‚¬ëŒë“¤ì´ ê³µê°í•˜ëŠ” ê·€ì°®ì€ ì¼
5. **Emergent Behavior**: í•™ìŠµë˜ì§€ ì•Šì€ ì „ëµì´ ìì—°ìŠ¤ëŸ½ê²Œ ë‚˜íƒ€ë‚¨

---

## 2. Ï€0 vs RT-2 vs OpenVLA í•µì‹¬ ì°¨ì´

### ë¹„êµ í…Œì´ë¸”
| í•­ëª© | Ï€0 | RT-2 | OpenVLA |
|:---|:---|:---|:---|
| **Action Output** | âœ… Continuous (Flow-matching) | âŒ Discrete Tokens | âŒ Discrete Tokens |
| **Control Frequency** | **50Hz** | 1Hz | 5-15Hz |
| **ì í•©í•œ íƒœìŠ¤í¬** | Long-horizon, **multi-step** ì‘ì—… | Single-instruction ì¼ë°˜í™” | Multi-object, single-step |
| **ê°•ì ** | **Smooth trajectory**, Real-time dexterity | Web knowledge í™œìš©, ì¶”ë¡  ëŠ¥ë ¥ | Multi-task, ë¹ ë¥¸ fine-tuning |
| **ì•½ì ** | ë°ì´í„° ë§ì´ í•„ìš” | ëŠë¦¼, ë¶€ë“œëŸ¬ìš´ ë™ì‘ ì–´ë ¤ì›€ | ë§ˆì°¬ê°€ì§€ë¡œ smooth motion ì•½í•¨ |

### Flow-matchingì˜ ê²°ì •ì  ì´ì 
1. **Smoothness**: ëŠê¸°ì§€ ì•ŠëŠ” ë¶€ë“œëŸ¬ìš´ ê¶¤ì  (Jerk ìµœì†Œí™”)
2. **Real-time**: 50Hz = 20ms per action â†’ Reactive control ê°€ëŠ¥
3. **Efficiency**: Diffusionë³´ë‹¤ ~85% ë¹ ë¥¸ ì¶”ë¡  ì†ë„
4. **Precision**: Continuous output â†’ ì •ë°€í•œ í˜/ì†ë„ ì œì–´

---

## 3. Flow-matchingì„ í™œìš©í•˜ê¸° ìµœì ì¸ Task íŠ¹ì„±

### âœ… Flow-matchingì´ ë¹›ë‚˜ëŠ” Task
1. **Deformable Object Manipulation** (ì˜·, ì²œ, ì¼€ì´ë¸”)
   - ì´ìœ : ë¶€ë“œëŸ¬ìš´ í˜ ì¡°ì ˆ í•„ìˆ˜, Discrete actionìœ¼ë¡œëŠ” ëŠê¹€
   
2. **Contact-rich Manipulation** (ë°€ê¸°, ì“¸ê¸°, ë¬¸ì§€ë¥´ê¸°)
   - ì´ìœ : ì—°ì†ì ì¸ í˜ í”¼ë“œë°±, 50Hzë¡œ ì‹¤ì‹œê°„ ë°˜ì‘
   
3. **Long-horizon Multi-step** (ìš”ë¦¬, ì²­ì†Œ, ì¡°ë¦½)
   - ì´ìœ : ì—¬ëŸ¬ primitiveì˜ ë¶€ë“œëŸ¬ìš´ ì „í™˜
   
4. **Fine-grained Speed Control** (ë¶€ì‚¬ ì œì–´!)
   - ì´ìœ : Continuous velocity â†’ "carefully" = 0.25 m/s ì •ë°€ ì œì–´

5. **Dynamic Interaction** (ìŸê¸°, ë”°ë¥´ê¸°, í”ë“¤ê¸°)
   - ì´ìœ : ì†ë„/ê°€ì†ë„ í”„ë¡œíŒŒì¼ì´ ê²°ê³¼ì— ì§ì ‘ ì˜í–¥

### âŒ Flow-matchingì´ ë¶ˆí•„ìš”í•œ Task
1. **Static Pick & Place** (ë‹¨ìˆœ ì§‘ê¸°/ë†€ê¸°)
   - OpenVLAë¡œë„ ì¶©ë¶„, Flow-matching ì˜¤ë²„í‚¬
   
2. **Waypoint Navigation** (ì§€ì  ì´ë™ë§Œ)
   - ê¶¤ì ì´ ë‹¨ìˆœí•´ì„œ discreteë„ OK

---

## 4. Dobot E6ë¡œ êµ¬í˜„ ê°€ëŠ¥í•œ "Ï€0-style" Task í›„ë³´

### ğŸ¯ ìµœì¢… ì œì•ˆ: "Flow-matchingì˜ ê°•ì ì„ í™œìš©í•œ Task Suite"

#### **Task A: Contact-rich Manipulation** â­â­â­â­â­
**ì˜ˆì‹œ**: "Wipe the table **gently**", "Push debris **carefully** toward the edge"

**Ï€0 ê°•ì  í™œìš©**:
- Continuous force control â†’ í…Œì´ë¸” ì†ìƒ ì—†ì´ ë¯¼ê°í•˜ê²Œ ì¡°ì ˆ
- Adverb â†’ ì†ë„/ì••ë ¥ ì§ì ‘ ë§¤í•‘ (Flow-matchingì˜ continuous output í™œìš©)

**Dobot E6 ì í•©ì„±**: âœ… (ê·¸ë¦¬í¼ ëŒ€ì‹  wiper ë¶€ì°©)

**ë°ì´í„°**: Simì—ì„œ ë‹¤ì–‘í•œ í…Œì´ë¸” í‘œë©´, ë¨¼ì§€ íŒ¨í„´ ìƒì„± ê°€ëŠ¥

---

#### **Task B: Pouring with Style Control** â­â­â­â­â­
**ì˜ˆì‹œ**: "Pour water **slowly**", "Fill the cup **carefully** without spilling"

**Ï€0 ê°•ì  í™œìš©**:
- Flow-matching â†’ ì†ë„ í”„ë¡œíŒŒì¼ ì •ë°€ ì œì–´ (ìŸì§€ ì•Šê¸°)
- 50Hz â†’ ì‹¤ì‹œê°„ ì»µ ê¸°ìš¸ê¸° ì¡°ì ˆ

**Dobot E6 ì í•©ì„±**: âš ï¸ (ì„¼ì„œ ë¶€ì¡±í•˜ì§€ë§Œ ì‹œê° ê¸°ë°˜ìœ¼ë¡œ ê°€ëŠ¥)

**ì°¨ë³„ì **: **ê¸°ì¡´ VLAê°€ ëª» í•˜ëŠ” íƒœìŠ¤í¬!** (Discrete tokenizationìœ¼ë¡œëŠ” ë¶ˆê°€ëŠ¥)

---

#### **Task C: Sequential Folding (Simplified Laundry)** â­â­â­â­
**ì˜ˆì‹œ**: "Fold the towel **neatly**"

**Ï€0 ê°•ì  í™œìš©**:
- Deformable object (ì²œ ìˆ˜ê±´)
- Multi-step: Grasp â†’ Align â†’ Fold â†’ Press
- Smooth transition between steps

**Dobot E6 ì í•©ì„±**: âœ… (ìˆ˜ê±´ í¬ê¸° ì œí•œ, 300g ì´í•˜)

**ë°ì´í„°**: Ï€0ì²˜ëŸ¼ ë¬´í•œí•œ ì´ˆê¸° ìƒíƒœ â†’ Generalization ê·¹í•œ ê²€ì¦

---

#### **Task D: Real-time Correction (ê¸°ì¡´ ìœ ì§€)** â­â­â­â­â­
**ì˜ˆì‹œ**: ë™ì‘ ì¤‘ "Slower", "Gentler" í”¼ë“œë°±

**Ï€0 ê°•ì  í™œìš©**:
- 50Hz â†’ ì‹¤ì‹œê°„ ë°˜ì‘ (RT-2ëŠ” 1Hzë¼ ë¶ˆê°€ëŠ¥)
- Continuous output â†’ Delta velocity ì¦‰ì‹œ ì ìš©

---

## 5. ê¸°ì¡´ ê³„íš vs Ï€0-ê¸°ë°˜ ê³„íš ë¹„êµ

### ê¸°ì¡´ ê³„íš (ì¼ë°˜ VLA ì ‘ê·¼)
| Task | ì°¨ë³„ì  | Ï€0 í™œìš©ë„ |
|:---|:---|:---:|
| Pick & Place + Adverb | Adverb ì œì–´ | â­â­ (OpenVLAë¡œë„ ê°€ëŠ¥) |
| Push with Adverb | ìŠ¤í‚¬ í™•ì¥ | â­â­â­ (Contact-rich) |
| Correction | Real-time | â­â­â­â­â­ |

### Ï€0 ê¸°ë°˜ ì‹ ê·œ ê³„íš
| Task | ì°¨ë³„ì  | Ï€0 í™œìš©ë„ | ê¸°ì¡´ VLAì™€ ì°¨ë³„ì„± |
|:---|:---|:---:|:---|
| **Contact-rich Wiping** | Continuous force | â­â­â­â­â­ | âœ… High |
| **Pouring with Style** | Speed profile | â­â­â­â­â­ | âœ… **Very High** |
| **Towel Folding** | Deformable | â­â­â­â­ | âœ… High |
| **Real-time Correction** | 50Hz reactive | â­â­â­â­â­ | âœ… Very High |

---

## 6. ìµœì¢… ê¶Œì¥ì‚¬í•­

### ì¶”ì²œ ì „ëµ: "Ï€0ì˜ ê°•ì ì— ì§‘ì¤‘"

#### Phase 1 (P0): **Pouring + Wiping**
- **Pouring**: ê¸°ì¡´ VLAê°€ ëª» í•˜ëŠ” ì˜ì—­, ë…¼ë¬¸ ì„íŒ©íŠ¸ ìµœê³ 
- **Wiping**: Contact-rich manipulation ê²€ì¦
- **ê³µí†µì **: ë‘˜ ë‹¤ **Continuous velocity control** í•„ìˆ˜

#### Phase 2 (P1): **Towel Folding**
- Ï€0 ëŒ€í‘œ Taskì˜ Simplified version
- Deformable object handling ê²€ì¦

#### Phase 3 (P2): **Real-time Correction**
- ëª¨ë“  Taskì— ì ìš© ê°€ëŠ¥í•œ General feature

---

### ë³€ê²½ ì´ìœ 
1. âŒ **ê¸°ì¡´**: Pick & PlaceëŠ” ë„ˆë¬´ basic, OpenVLAë„ ì˜í•¨
2. âœ… **ì‹ ê·œ**: Pouring/Wipingì€ **Flow-matching í•„ìˆ˜**, ì°¨ë³„í™” ê·¹ëŒ€í™”
3. âœ… **ë…¼ë¬¸ ê°€ì¹˜**: "ìš°ë¦¬ë§Œ í•  ìˆ˜ ìˆëŠ” ê²ƒ"ì„ ë³´ì—¬ì¤˜ì•¼ Top Conference

---

## 7. êµ¬í˜„ ë‚œì´ë„ ì¬í‰ê°€

### Pouring Task
| í•­ëª© | ë‚œì´ë„ | ëŒ€ì‘ ë°©ì•ˆ |
|:---|:---:|:---|
| ì„¼ì„œ ë¶€ì¡± (í˜/ìœ ëŸ‰) | â­â­â­â­ | Vision-based: ì»µ ì±„ì›Œì§„ ì •ë„ ì¸ì‹ |
| Sim2Real Gap (ì•¡ì²´ ë¬¼ë¦¬) | â­â­â­â­â­ | Isaac Simì˜ Particle system í™œìš© |
| ì•ˆì „ì„± (ìŸì„ ìœ„í—˜) | â­â­â­ | ë¬¼ ëŒ€ì‹  êµ¬ìŠ¬, ë‚˜ì¤‘ì— ë¬¼ |

**ì´ ë‚œì´ë„**: â­â­â­â­ (ë„ì „ì ì´ì§€ë§Œ ê°€ì¹˜ ìˆìŒ)

### Wiping Task
| í•­ëª© | ë‚œì´ë„ | ëŒ€ì‘ ë°©ì•ˆ |
|:---|:---:|:---|
| End-effector êµì²´ | â­â­ | Wiper ì œì‘ (3D í”„ë¦°íŒ…) |
| Force control | â­â­â­ | Position-based implicit force |
| í‰ê°€ ë©”íŠ¸ë¦­ (ì–¼ë§ˆë‚˜ ê¹¨ë—í•œì§€) | â­â­â­ | Vision: ë¨¼ì§€ í”½ì…€ ì¹´ìš´íŠ¸ |

**ì´ ë‚œì´ë„**: â­â­â­ (ì ë‹¹í•¨)

---

## ê²°ë¡ 

**Ï€0ë¥¼ ì“°ë ¤ë©´ Ï€0ë§Œ í•  ìˆ˜ ìˆëŠ” ê²ƒì„ í•´ì•¼ í•©ë‹ˆë‹¤.**

- âŒ Pick & PlaceëŠ” ëª¨ë“  VLAê°€ í•˜ëŠ” ê²ƒ
- âœ… **Pouring**, **Wiping**, **Folding**ì€ **Flow-matching ì—†ì´ëŠ” ì–´ë ¤ìš´ Task**
- âœ… ìš°ë¦¬ì˜ ì°¨ë³„ì : "**ì–´ë–»ê²Œ(How)**" â†’ Continuous controlì˜ ì •ìˆ˜

**ë‹¤ìŒ ë‹¨ê³„**: ì´ ë°©í–¥ìœ¼ë¡œ ì§„í–‰í• ì§€ ê²°ì • í›„, Pouring/Wiping í™˜ê²½ êµ¬ì¶• ì‹œì‘


---


# VLA Task Suite í‰ê°€ ë° ì¡°í•© ë¶„ì„

> **ì‘ì„±ì¼**: 2026-01-02  
> **ëª©ì **: 3ê°€ì§€ VLA íƒœìŠ¤í¬ì˜ ì´ë¡ ì  íƒ€ë‹¹ì„± í‰ê°€ ë° í•„ìš” ë°ì´í„° ê°€ì§“ìˆ˜ ì‚°ì¶œ

---

## 1. Task í‰ê°€ Framework

### í‰ê°€ ê¸°ì¤€
1. **í•™ìˆ ì  ì°¸ì‹ ì„±**: ê¸°ì¡´ VLA ì—°êµ¬ì™€ì˜ ì°¨ë³„ì 
2. **êµ¬í˜„ ë‚œì´ë„**: ë°ì´í„° ìˆ˜ì§‘, í•™ìŠµ, í‰ê°€ì˜ ì–´ë ¤ì›€
3. **ì„±ê³µ ê°€ëŠ¥ì„±**: Sim2Real transfer ìœ„í—˜ë„ ê³ ë ¤
4. **ì—°êµ¬ ê¸°ì—¬ë„**: ë…¼ë¬¸ ì¶œíŒ ê°€ëŠ¥ì„±

### ë‚œì´ë„ ì²™ë„
- â­ (ë§¤ìš° ì‰¬ì›€) ~ â­â­â­â­â­ (ë§¤ìš° ì–´ë ¤ì›€)

---

## 2. ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ Task í›„ë³´ ì„ ì •

### Category 1: ì¡°ì‘ ìŠ¤í‚¬ íƒ€ì… (Manipulation Skills)

| ìŠ¤í‚¬ | ì„¤ëª… | Dobot E6 ì í•©ì„± | í•„ìš” ì¥ë¹„ | ì„ ì • ì—¬ë¶€ |
|:---|:---|:---:|:---|:---:|
| **Pick** | ë¬¼ì²´ ì§‘ê¸° | âœ… ë§¤ìš° ì í•© | Gripper | â­â­â­â­â­ ì±„íƒ |
| **Place** | ë¬¼ì²´ ë†“ê¸° | âœ… ë§¤ìš° ì í•© | - | â­â­â­â­â­ ì±„íƒ |
| **Push** | ë¬¼ì²´ ë°€ê¸° | âœ… ì í•© | - | â­â­â­â­ ì±„íƒ |
| **Pour** | ì•¡ì²´ ë”°ë¥´ê¸° | âš ï¸ ì œí•œì  | ì»µ, ì•¡ì²´ | â­â­ ë³´ë¥˜ (ì„¼ì„œ ë¶€ì¡±) |
| **Flip** | ë’¤ì§‘ê¸° | âš ï¸ ì œí•œì  | íŠ¹ìˆ˜ ê·¸ë¦¬í¼ | â­ ë³´ë¥˜ (ì •ë°€ë„ ë¶€ì¡±) |
| **Stack** | ìŒ“ê¸° | âœ… ì í•© | ë¸”ë¡ | â­â­â­â­ í›„ë³´ |
| **Slide** | ë°€ì–´ì„œ ì´ë™ | âœ… ì í•© | í‰í‰í•œ í‘œë©´ | â­â­â­ í›„ë³´ |
| **Insert** | ë¼ìš°ê¸° | âš ï¸ ë„ì „ì  | êµ¬ë©ì´ ìˆëŠ” ë¬¼ì²´ | â­â­ ë³´ë¥˜ (ì •ë°€ë„ ìš”êµ¬) |

**ì„ ì • ì´ìœ **:
- **Pick, Place, Push**: Dobot E6ì˜ Â±0.1mm ë°˜ë³µ ì •ë°€ë„ë¡œ ì¶©ë¶„íˆ ìˆ˜í–‰ ê°€ëŠ¥
- **Stack, Slide**: ì¶”ê°€ íƒœìŠ¤í¬ë¡œ í™•ì¥ ê°€ëŠ¥, ìƒˆë¡œìš´ ìŠ¤í‚¬ í•™ìŠµ ê²€ì¦
- **Pour, Insert**: Force/Torque ì„¼ì„œ ì—†ì–´ ì‹¤íŒ¨ ìœ„í—˜ ë†’ìŒ

---

### Category 2: ì–¸ì–´ ì œì–´ ì°¨ì› (Language Control Dimensions)

| ì°¨ì› | ì˜ˆì‹œ | VLA ê¸°ì—¬ë„ | êµ¬í˜„ ë‚œì´ë„ | ì„ ì • ì—¬ë¶€ |
|:---|:---|:---:|:---:|:---:|
| **What** (ë¬¼ì²´) | "Pick the **red** cup" | â­â­ | â­ | âœ… ê¸°ë³¸ |
| **Where** (ìœ„ì¹˜) | "Place it **on the left**" | â­â­ | â­ | âœ… ê¸°ë³¸ |
| **How** (ìŠ¤íƒ€ì¼) | "Move **carefully**" | â­â­â­â­â­ | â­â­ | â­â­â­â­â­ í•µì‹¬ |
| **When** (íƒ€ì´ë°) | "Stop **when** it touches" | â­â­â­â­ | â­â­â­â­ | â­â­ ë³´ë¥˜ |
| **Correction** | "Move it **more to the right**" | â­â­â­â­â­ | â­â­â­â­ | â­â­â­â­â­ í•µì‹¬ |
| **Sequence** | "**First** pick, **then** place" | â­â­â­ | â­â­â­ | â­â­â­ í›„ë³´ |

**ì„ ì • ì´ìœ **:
- **How (Adverb)**: ê¸°ì¡´ VLAê°€ ë‹¤ë£¨ì§€ ì•Šì€ ì˜ì—­, ì°¸ì‹ ì„± ìµœê³ 
- **Correction**: Real-time HRIì— í•„ìˆ˜, í•™ìˆ ì  ê°€ì¹˜ ë§¤ìš° ë†’ìŒ
- **When (íƒ€ì´ë°)**: Contact sensing ì—†ì–´ êµ¬í˜„ ì–´ë ¤ì›€
- **Sequence**: ì´ë¯¸ ê¸°ì¡´ VLAê°€ ë‹¤ë£¸, ì°¨ë³„ì„± ë‚®ìŒ

---

### Category 3: ë¬¼ì²´ ì†ì„± (Object Properties)

| ì†ì„± | ë³€í˜• ê°€ëŠ¥ì„± | Sim2Real ë‚œì´ë„ | ì„ ì • ì—¬ë¶€ |
|:---|:---:|:---:|:---:|
| **Rigid (ê°•ì²´)** | Cube, Sphere, Cylinder | â­ | â­â­â­â­â­ í•„ìˆ˜ |
| **Color** | Red, Blue, Green, Yellow | â­ | â­â­â­â­â­ í•„ìˆ˜ |
| **Size** | Small (5cm), Medium (10cm) | â­â­ | â­â­â­â­ ì±„íƒ |
| **Weight** | Light (<300g), Heavy (300-750g) | â­â­â­ | â­â­â­ í›„ë³´ |
| **Deformable** | ì²œ, ìŠ¤í°ì§€ | â­â­â­â­â­ | â­ ì œì™¸ (Sim ì–´ë ¤ì›€) |
| **Articulated** | ì„œë, ë¬¸ | â­â­â­â­ | â­â­ ì œì™¸ (ë³µì¡ë„) |

**Payload ì œì•½ ê³ ë ¤**:
- Dobot E6: ìµœëŒ€ 0.75kg â†’ ë¬´ê±°ìš´ ë¬¼ì²´ëŠ” ì‹ ì¤‘íˆ ì„ íƒ
- **ê¶Œì¥**: 300g ì´í•˜ ë¬¼ì²´ ìœ„ì£¼ (ì»µ, ë¸”ë¡, ì‘ì€ ê³µêµ¬)

---

### Category 4: ë‚œì´ë„ ë ˆë²¨ (Difficulty Levels)

| Level | Task ì˜ˆì‹œ | ì„±ê³µë¥  ì˜ˆìƒ | í•™ìŠµ Episodes | ì„ ì • |
|:---:|:---|:---:|:---:|:---:|
| **L1 (Easy)** | Reach fixed target | 95%+ | 50 | âœ… Warmup |
| **L2 (Medium)** | Pick & Place static object | 80-90% | 200 | â­â­â­â­â­ í•µì‹¬ |
| **L3 (Hard)** | Pick with Adverb control | 70-85% | 300 | â­â­â­â­â­ í•µì‹¬ |
| **L4 (Very Hard)** | Real-time correction | 60-75% | 100 (ì‚¬ëŒ) | â­â­â­â­ í›„ë³´ |
| **L5 (Extreme)** | Dynamic object catching | <50% | 1000+ | âŒ ì œì™¸ |

**êµ¬í˜„ ì „ëµ**:
1. L1 â†’ L2 â†’ L3 ìˆœì°¨ êµ¬í˜„ (Curriculum Learning)
2. L4ëŠ” L3 ì„±ê³µ í›„ ì¶”ê°€

---

### Category 5: í‰ê°€ ë©”íŠ¸ë¦­ ì¹´í…Œê³ ë¦¬ (Evaluation Metrics)

| ë©”íŠ¸ë¦­ | ì¸¡ì • ë°©ë²• | ì ìš© Task | ìš°ì„ ìˆœìœ„ |
|:---|:---|:---|:---:|
| **Success Rate** | Goal region ë„ë‹¬ ì—¬ë¶€ | All tasks | â­â­â­â­â­ |
| **Execution Time** | ì‹œì‘~ë ì‹œê°„ | Adverb task | â­â­â­â­ |
| **Collision Count** | ì¶©ëŒ ê°ì§€ íšŸìˆ˜ | All tasks | â­â­â­â­ |
| **Trajectory Smoothness** | Jerk í‘œì¤€í¸ì°¨ | Adverb task | â­â­â­ |
| **Correction Latency** | í”¼ë“œë°±~ë°˜ì‘ ì‹œê°„ | Correction task | â­â­â­â­â­ |
| **Generalization** | ìƒˆ ë¬¼ì²´ ì„±ê³µë¥  | All tasks | â­â­â­â­ |

---

### ìµœì¢… ì„ ì • Task Suite (ìš°ì„ ìˆœìœ„ ê¸°ë°˜)

| ìˆœìœ„ | Task Name | ìŠ¤í‚¬ ì¡°í•© | ì–¸ì–´ ì°¨ì› | ë‚œì´ë„ | ë¹„ê³  |
|:---:|:---|:---|:---|:---:|:---|
| **1** | Pick & Place + Adverb | Pick, Place | What, Where, How | L3 | í•µì‹¬ íƒœìŠ¤í¬ |
| **2** | Push with Adverb | Push | What, Where, How | L2 | í™•ì¥ ìŠ¤í‚¬ |
| **3** | Real-time Correction | Pick/Place | Correction | L4 | ì°¸ì‹ ì„± ìµœê³  |
| **4** | Stack Blocks | Pick, Place, Stack | What, Where | L3 | ì¶”ê°€ ê²€ì¦ìš© |

---

## 3. Task 1: Pick-and-Place with Language Variations

### í•™ìˆ ì  ê·¼ê±°
- **ê¸°ì¡´ ì—°êµ¬**: RT-2, OpenVLA, Octo ë“± ëŒ€ë¶€ë¶„ Pick & Place í¬í•¨
- **ìš°ë¦¬ì˜ ì°¨ë³„ì **:
  1. **Adverb conditioning** (ê¸°ì¡´ ì—°êµ¬ëŠ” "What"ë§Œ ë‹¤ë£¸, ìš°ë¦¬ëŠ” "How"ë„)
  2. **Small-scale robot** (Dobot E6)ì—ì„œì˜ VLA ê²€ì¦
  3. **Sim2Real with limited real data** (Real 50 demosë§Œìœ¼ë¡œ transfer)

### ì‹¤ì œ ë°ì´í„° ì¡°í•© ê°€ì§“ìˆ˜

#### Isaac Simì—ì„œ ìƒì„± ê°€ëŠ¥í•œ ì¡°í•©
| ë³€ìˆ˜ | ê°€ì§“ìˆ˜ | ì„¤ëª… |
|:---|:---:|:---|
| **ë¬¼ì²´ ì¢…ë¥˜** | 4 | Cube, Cylinder, Sphere, Box |
| **ë¬¼ì²´ ìƒ‰ìƒ** | 4 | Red, Blue, Green, Yellow |
| **ì´ˆê¸° ìœ„ì¹˜** | 5x5 = 25 | í…Œì´ë¸” ê·¸ë¦¬ë“œ |
| **ëª©í‘œ ìœ„ì¹˜** | 3 | Left/Center/Right platform |
| **Adverb** | 3 | carefully, quickly, normal |

**ì´ ì¡°í•© ìˆ˜**: 4 x 4 x 25 x 3 x 3 = **3,600 ê°€ì§€**

#### ì‹¤ì œ ìˆ˜ì§‘ ê³„íš
- **Sim**: 200 episodes (ì•½ 5.5% ìƒ˜í”Œë§)
- **Real**: 50 episodes (ëŒ€í‘œì ì¸ ì¡°í•©ë§Œ)

### êµ¬í˜„ ë‚œì´ë„ í‰ê°€
| í•­ëª© | ë‚œì´ë„ | ê·¼ê±° |
|:---|:---:|:---|
| Isaac Sim í™˜ê²½ êµ¬ì¶• | â­â­ | Dobot E6 URDF ì œê³µ, ê¸°ì¡´ ì˜ˆì œ ë§ìŒ |
| ë°ì´í„° ìˆ˜ì§‘ (Sim) | â­ | Scripted policyë¡œ ìë™í™” |
| ë°ì´í„° ìˆ˜ì§‘ (Real) | â­â­â­ | Drag-to-teach ë°˜ë³µ ì‘ì—… í•„ìš” |
| í•™ìŠµ ì•ˆì •ì„± | â­â­ | Flow-matchingì€ ë¹„êµì  ì•ˆì •ì  |
| Sim2Real Gap | â­â­â­â­ | ë¬¼ë¦¬ì  ì†ì„± ì°¨ì´, ê·¸ë¦¬í¼ ë¶ˆí™•ì‹¤ì„± |

**ì´ ë‚œì´ë„**: â­â­â­ (ì¤‘ê°„)

### ì—°êµ¬ ê¸°ì—¬ë„
- **Novelty**: â­â­â­ (Adverb controlì´ ì°¸ì‹ í•˜ì§€ë§Œ taskëŠ” ê¸°ë³¸ì )
- **Impact**: â­â­â­â­ (Small robot VLAëŠ” ì‹¤ìš©ì  ê°€ì¹˜ ë†’ìŒ)
- **ë…¼ë¬¸ ê°€ëŠ¥ì„±**: â­â­â­â­ (Conferenceê¸‰ ê°€ëŠ¥, Workshop í™•ì‹¤)

---

## 3. Task 2: Real-time Language Correction

### í•™ìˆ ì  ê·¼ê±°
- **ê¸°ì¡´ ì—°êµ¬**: 
  - **ExTraCT** (Frontiers in Robotics): ì–¸ì–´ â†’ ê¶¤ì  ìˆ˜ì • í•¨ìˆ˜
  - **IRP** (RSS): Residual Policy Learning
- **ìš°ë¦¬ì˜ ì°¨ë³„ì **:
  1. **Real-time feedback** (ê¸°ì¡´ì€ ì‚¬ì „ ê³„íš ë‹¨ê³„)
  2. **Flow-matching + Residual** ê²°í•© (Novel architecture)
  3. **Human-in-the-loop dataset** (ì‚¬ëŒì´ ì§ì ‘ ê°œì…í•˜ëŠ” ë°ì´í„°)

### ì‹¤ì œ ë°ì´í„° ì¡°í•© ê°€ì§“ìˆ˜

#### Correction ì‹œë‚˜ë¦¬ì˜¤ ì¡°í•©
| ë³€ìˆ˜ | ê°€ì§“ìˆ˜ | ì„¤ëª… |
|:---|:---:|:---|
| **Base Task** | 3 | Reach, Pick, Place |
| **Correction ë°©í–¥** | 6 | Left, Right, Up, Down, Forward, Back |
| **Correction ì‹œì ** | 3 | Early (20%), Mid (50%), Late (80%) |
| **Correction ê°•ë„** | 2 | Small (Â±3cm), Large (Â±8cm) |

**ì´ ì¡°í•© ìˆ˜**: 3 x 6 x 3 x 2 = **108 ê°€ì§€**

#### ì‹¤ì œ ìˆ˜ì§‘ ê³„íš
- **Sim**: ë¶ˆê°€ëŠ¥ (ì‚¬ëŒì˜ íŒë‹¨ì´ í•„ìš”)
- **Real Human-in-the-loop**: 100 trials
  - 10ëª… x 10 trials = 100 (ì¡°í•© ì¤‘ 91%ë¥¼ ì»¤ë²„)

### êµ¬í˜„ ë‚œì´ë„ í‰ê°€
| í•­ëª© | ë‚œì´ë„ | ê·¼ê±° |
|:---|:---:|:---|
| ë°ì´í„° ìˆ˜ì§‘ | â­â­â­â­â­ | ì‚¬ëŒì´ ì‹¤ì‹œê°„ìœ¼ë¡œ ê°œì…í•´ì•¼ í•¨ |
| ì–¸ì–´ í”¼ë“œë°± ì¸ì½”ë”© | â­â­ | CLIP/BERTë¡œ ê°„ë‹¨íˆ ì²˜ë¦¬ |
| Residual Head í•™ìŠµ | â­â­ | êµ¬ì¡° ë‹¨ìˆœ, ë°ì´í„°ë§Œ ìˆìœ¼ë©´ OK |
| Real-time ì„±ëŠ¥ | â­â­â­â­ | 50Hz ìœ ì§€ ì–´ë ¤ì›€ (VL Encoder ë³‘ëª©) |
| í‰ê°€ ë©”íŠ¸ë¦­ ì •ëŸ‰í™” | â­â­â­ | "ì–¼ë§ˆë‚˜ ì˜ ìˆ˜ì •í–ˆë‚˜?" ëª¨í˜¸í•¨ |

**ì´ ë‚œì´ë„**: â­â­â­â­ (ì–´ë ¤ì›€)

### ì—°êµ¬ ê¸°ì—¬ë„
- **Novelty**: â­â­â­â­â­ (Real-time correctionì€ ê±°ì˜ ì—°êµ¬ ì•ˆ ë¨)
- **Impact**: â­â­â­â­ (HRI ê´€ì ì—ì„œ ë§¤ìš° ì¤‘ìš”)
- **ë…¼ë¬¸ ê°€ëŠ¥ì„±**: â­â­â­â­â­ (Top-tier Conference ê°€ëŠ¥, CoRL/ICRA)

**âš ï¸ ë¦¬ìŠ¤í¬**: ë°ì´í„° ìˆ˜ì§‘ ë‚œì´ë„ê°€ ë§¤ìš° ë†’ì•„ í”„ë¡œì íŠ¸ ì§€ì—° ê°€ëŠ¥

---

## 4. Task 3: Adverb-Conditioned Speed Control

### í•™ìˆ ì  ê·¼ê±°
- **ê¸°ì¡´ ì—°êµ¬**:
  - **Language-to-Velocity Mapping** (CMU, arXiv)
  - **Motion Style Transfer** (Dartmouth)
- **ìš°ë¦¬ì˜ ì°¨ë³„ì **:
  1. **VLAì— Style Token í†µí•©** (ê¸°ì¡´ì€ ë³„ë„ ëª¨ë“ˆ)
  2. **Auto-labeling pipeline** (ì†ë„ â†’ ë¶€ì‚¬ ìë™ ë§¤í•‘)
  3. **ì‹¤ì œ ë¡œë´‡ ê²€ì¦** (ê¸°ì¡´ì€ ëŒ€ë¶€ë¶„ Simë§Œ)

### ì‹¤ì œ ë°ì´í„° ì¡°í•© ê°€ì§“ìˆ˜

#### Adverb Style ì¡°í•©
| ë³€ìˆ˜ | ê°€ì§“ìˆ˜ | ì„¤ëª… |
|:---|:---:|:---|
| **ë¶€ì‚¬ ì¢…ë¥˜** | 4 | carefully, quickly, steadily, normal |
| **Base Task** | 5 | Reach, Pick, Place, Push, Move |
| **ë¬¼ì²´/ëª©í‘œ** | 8 | Task 1ê³¼ ë™ì¼í•œ ë¬¼ì²´ ì¡°í•© |

**ì´ ì¡°í•© ìˆ˜**: 4 x 5 x 8 = **160 ê°€ì§€**

#### ì‹¤ì œ ìˆ˜ì§‘ ê³„íš
- **Sim**: 200 episodes (125% ì˜¤ë²„ìƒ˜í”Œë§ìœ¼ë¡œ ëª¨ë“  ì¡°í•© ì»¤ë²„)
- **Real**: 20 episodes (ë¶€ì‚¬ë‹¹ 5ê°œ, ëŒ€í‘œ íƒœìŠ¤í¬ë§Œ)

### Auto-labeling ì „ëµ

#### ì†ë„ ê¸°ë°˜ ë¶€ì‚¬ ë¶„ë¥˜
```python
def classify_adverb(trajectory):
    avg_velocity = compute_avg_velocity(trajectory)
    jerk_std = compute_jerk_std(trajectory)
    
    if avg_velocity < 0.15 and jerk_std < 0.05:
        return "carefully"
    elif avg_velocity > 0.35:
        return "quickly"
    elif jerk_std < 0.03:
        return "steadily"
    else:
        return "normal"
```

**Auto-labeling ì •í™•ë„ ì˜ˆìƒ**: 85-90% (ìˆ˜ë™ ê²€ì¦ í•„ìš”)

### êµ¬í˜„ ë‚œì´ë„ í‰ê°€
| í•­ëª© | ë‚œì´ë„ | ê·¼ê±° |
|:---|:---:|:---|
| Isaac Sim í™˜ê²½ | â­ | Task 1ê³¼ ê³µìœ  |
| Auto-labeling ìŠ¤í¬ë¦½íŠ¸ | â­â­ | ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹± |
| Style Token í†µí•© | â­â­ | Architecture ìˆ˜ì • í•„ìš” |
| í•™ìŠµ ì•ˆì •ì„± | â­â­ | Multi-task learning ìˆ˜ì¤€ |
| í‰ê°€ (ì†ë„ ìƒê´€ê´€ê³„) | â­ | Pearson r ê³„ì‚°í•˜ë©´ ë¨ |

**ì´ ë‚œì´ë„**: â­â­ (ì‰¬ì›€)

### ì—°êµ¬ ê¸°ì—¬ë„
- **Novelty**: â­â­â­ (Adverb controlì€ ìƒˆë¡­ì§€ë§Œ ê°œë…ì€ ê¸°ì¡´ ì—°êµ¬ í™•ì¥)
- **Impact**: â­â­â­ (ì‹¤ìš©ì ì´ì§€ë§Œ í˜ì‹ ì ì´ì§„ ì•ŠìŒ)
- **ë…¼ë¬¸ ê°€ëŠ¥ì„±**: â­â­â­ (Workshop ê¸‰, Task 1ê³¼ í•¨ê»˜ ë¬¶ì–´ì•¼ Conference)

---

## 5. ì¢…í•© ë¹„êµ ë° ìš°ì„ ìˆœìœ„

### ë¹„êµ í…Œì´ë¸”
| Task | ë‚œì´ë„ | ì°¸ì‹ ì„± | ê¸°ì—¬ë„ | ë°ì´í„° í•„ìš”ëŸ‰ | ìš°ì„ ìˆœìœ„ |
|:---|:---:|:---:|:---:|:---:|:---:|
| **Task 1: Pick & Place** | â­â­â­ | â­â­â­ | â­â­â­â­ | 250 episodes | **P0** |
| **Task 2: Correction** | â­â­â­â­ | â­â­â­â­â­ | â­â­â­â­â­ | 100 episodes | **P1** |
| **Task 3: Adverb** | â­â­ | â­â­â­ | â­â­â­ | 220 episodes | **P1** |

### ì¶”ì²œ êµ¬í˜„ ì „ëµ

#### Phase 1 (Week 1-4): Task 1 + Task 3 í†µí•©
- **ì´ìœ **: ë‘˜ ë‹¤ Isaac Sim ë°ì´í„°ë¡œ í•™ìŠµ ê°€ëŠ¥
- **ëª©í‘œ**: Pick & Place with Adverb Control ì™„ì„±
- **Deliverable**: Conference Workshop ë…¼ë¬¸ (4-6 pages)

#### Phase 2 (Week 5-8): Task 2 ì¶”ê°€
- **ì´ìœ **: ë°ì´í„° ìˆ˜ì§‘ì´ ì˜¤ë˜ ê±¸ë¦¼
- **ëª©í‘œ**: Real-time Correction ê¸°ëŠ¥ ê²€ì¦
- **Deliverable**: Full Conference Paper (8 pages)

---

## 6. í•„ìš” ë°ì´í„°ì…‹ ìš”ì•½

### ì´ ë°ì´í„° ìš”êµ¬ëŸ‰
| ì¶œì²˜ | Task 1 | Task 2 | Task 3 | í•©ê³„ |
|:---|:---:|:---:|:---:|:---:|
| **Isaac Sim** | 200 | 0 | 200 | 400 episodes |
| **Real Teleoperation** | 50 | 0 | 20 | 70 episodes |
| **Human Correction** | 0 | 100 | 0 | 100 episodes |
| **ì´ê³„** | 250 | 100 | 220 | **570 episodes** |

### ë°ì´í„° ìˆ˜ì§‘ ì˜ˆìƒ ì‹œê°„
- **Sim (ìë™)**: 400 episodes x 2 min/episode = **13.3 hours**
- **Real Teleoperation**: 70 episodes x 5 min/episode = **5.8 hours**
- **Human Correction**: 100 trials x 3 min/trial = **5 hours**
- **ì´ê³„**: **~24 hours** (ì‹¤ì œë¡œëŠ” ë””ë²„ê¹… ë“± í¬í•¨ 2-3ë°° ì†Œìš”)

---

## 7. ê²°ë¡  ë° ê¶Œì¥ì‚¬í•­

### ìµœìš°ì„  ì‘ì—… (ì´ë²ˆ ì£¼)
1. âœ… **Task 1 + Task 3 í†µí•© êµ¬í˜„**
   - ë‘˜ ë‹¤ Sim ë°ì´í„°ë¡œ í•™ìŠµ ê°€ëŠ¥
   - ë‚œì´ë„ ë‚®ê³  ë¹ ë¥¸ ì„±ê³¼ ê°€ëŠ¥
2. â¸ï¸ **Task 2ëŠ” í›„ìˆœìœ„**
   - Human-in-the-loop ë°ì´í„° ìˆ˜ì§‘ì´ ë³‘ëª©
   - ì´ˆê¸° ì„±ê³¼ ì´í›„ ì¶”ê°€

### ìœ„í—˜ ìš”ì†Œ
1. **Sim2Real Gap**: Domain randomization í•„ìˆ˜
2. **Real Robot ì ‘ê·¼ì„±**: Dobot E6ê°€ í•­ìƒ ì‚¬ìš© ê°€ëŠ¥í•œì§€ í™•ì¸ í•„ìš”
3. **ì‚¬ëŒ ì°¸ì—¬ì ëª¨ì§‘**: Task 2ë¥¼ ìœ„í•œ 10ëª… í™•ë³´

### ë…¼ë¬¸ ì¶œíŒ ì „ëµ
- **Option A (ì•ˆì „)**: Task 1 + 3ë§Œìœ¼ë¡œ Workshop ë…¼ë¬¸
- **Option B (ë„ì „)**: Task 1 + 2 + 3 í†µí•©í•˜ì—¬ Main Conference (CoRL, ICRA)


---


# Pouring & Wiping Task ì‹¬ì¸µ ì¡°ì‚¬

> **ì‘ì„±ì¼**: 2026-01-02  
> **ëª©ì **: Pouringê³¼ Wiping íƒœìŠ¤í¬ì˜ ê¸°ì¡´ ì—°êµ¬, êµ¬í˜„ ë°©ë²•, ì–´ë ¤ì›€, í‰ê°€ ë©”íŠ¸ë¦­ ë¶„ì„

---

## 1. Pouring Task ìƒì„¸ ë¶„ì„

### 1.1 ê¸°ì¡´ ì—°êµ¬ ì‚¬ë¡€

#### ì£¼ìš” ì—°êµ¬ í”„ë¡œì íŠ¸
| ì—°êµ¬/ì‹œìŠ¤í…œ | ì ‘ê·¼ë²• | í•µì‹¬ ê¸°ìˆ  |
|:---|:---|:---|
| **PourNet** (RL-based) | Deep RL + NMPC | Fluid dynamics í•™ìŠµ ì—†ì´ end-to-end |
| **PourIt!** | Visual Closed-loop | ì‹¤ì‹œê°„ ë¹„ì „ í”¼ë“œë°±ìœ¼ë¡œ pouring ì œì–´ |
| **UW Liquid Pouring Dataset** | Perception + Reasoning | Pixel-level liquid label ì‚¬ìš© |
| **VLA Pouring** (GPT-4V) | Vision-Language | Force/Torque â†’ Visionìœ¼ë¡œ ì ë„ ì¶”ë¡  |

#### í•µì‹¬ ë°œê²¬
- âœ… **VLA ì ìš© ì‚¬ë¡€ ìˆìŒ**: ì–¸ì–´ë¡œ "pour milk into cup" ê°™ì€ ì§€ì‹œ ê°€ëŠ¥
- âœ… **Learning-based ì„±ê³µ**: RL, Self-supervised learning ëª¨ë‘ íš¨ê³¼ì 
- âš ï¸ **Velocity Profile ì¤‘ìš”**: Slosh controlì— ì†ë„ í”„ë¡œíŒŒì¼ ìµœì í™” í•„ìˆ˜
- âš ï¸ **Sim2Real Gap í¼**: Fluid simulationì´ ì–´ë ¤ì›€

---

### 1.2 êµ¬í˜„ ë°©ë²•ë¡ 

#### A. Perception (ì•¡ì²´ ì¸ì‹)
```python
# ë¹„ì „ ê¸°ë°˜ ì•¡ì²´ ì¸ì‹ ë°©ë²•
methods = {
    "Volume Estimation": "RGB-Dë¡œ ì•¡ì²´ ë¶€í”¼ ì¶”ì •",
    "Surface Tracking": "ì•¡ì²´ í‘œë©´ ê²€ì¶œ ë° ì¶”ì ",
    "Level Detection": "ì»µ ì±„ì›€ ì •ë„ ì¸¡ì • (Â±mm ì •í™•ë„)",
    "Boundary Detection": "ì•¡ì²´ ê²½ê³„ ë° í˜•ìƒ ë³€í™” ê°ì§€"
}
```

**Dobot E6 ì ìš©**:
- âœ… Wrist cameraë¡œ ì»µ ë‚´ë¶€ ê´€ì°° ê°€ëŠ¥
- âœ… Overhead cameraë¡œ ì „ì²´ ì‘ì—… ê³µê°„ ëª¨ë‹ˆí„°ë§
- âŒ Force/Torque ì„¼ì„œ ì—†ìŒ â†’ Visionìœ¼ë¡œ ëŒ€ì²´ í•„ìˆ˜

---

#### B. Control Strategy

**1. Velocity Profile ê¸°ë°˜ ì œì–´**
```python
# Slosh ìµœì†Œí™”ë¥¼ ìœ„í•œ ì†ë„ í”„ë¡œíŒŒì¼
def optimal_pouring_profile(adverb):
    if adverb == "slowly":
        return {
            "tilt_speed": 5Â°/s,         # ì²œì²œíˆ ê¸°ìš¸ì´ê¸°
            "max_tilt": 45Â°,            # ìµœëŒ€ ê°ë„ ì œí•œ
            "deceleration": smooth      # ë¶€ë“œëŸ¬ìš´ ê°ì†
        }
    elif adverb == "quickly":
        return {
            "tilt_speed": 20Â°/s,
            "max_tilt": 60Â°,
            "deceleration": abrupt
        }
```

**2. Visual Feedback Control**
- Real-time: 50Hz ë¹„ì „ ì‹œìŠ¤í…œìœ¼ë¡œ ì•¡ì²´ Level ì¶”ì 
- Closed-loop: Level ëª©í‘œì¹˜ ë„ë‹¬ ì‹œ ìë™ ì¤‘ì§€
- Adaptive: ì•¡ì²´ íë¦„ ì†ë„ì— ë”°ë¼ ê¸°ìš¸ê¸° ë™ì  ì¡°ì ˆ

---

### 1.3 Isaac Sim Fluid Simulation

#### ê°€ëŠ¥í•œ ë°©ë²•
| ë°©ë²• | ì¥ì  | ë‹¨ì  | Dobot E6 ì ìš©ì„± |
|:---|:---|:---|:---:|
| **Particle System** | ë¬¼ë¦¬ ê¸°ë°˜, ì‹œê°ì  ë¦¬ì–¼ | ëŠë¦¼, íŒŒë¼ë¯¸í„° íŠœë‹ ì–´ë ¤ì›€ | âœ… ê°€ëŠ¥ |
| **Simplified Fluid** | ë¹ ë¦„, ì•ˆì •ì  | ì •í™•ë„ ë‚®ìŒ | âœ… í”„ë¡œí† íƒ€ì…ìš© |
| **Cylinder Animation** | ë§¤ìš° ë¹ ë¦„ | ë¬¼ë¦¬ ì—†ìŒ (ë†’ì´ë§Œ ë³€ê²½) | âš ï¸ í•™ìŠµìš© ë¶€ì í•© |

**Isaac Sim êµ¬ì²´ì  ë°©ë²•**:
```python
# Particle System ì„¤ì •
particle_system = ParticleSystem()
particle_set = ParticleSet(sampler="FluidVolumeSampler")
particle_set.set_properties(
    viscosity=0.001,      # ë¬¼
    density=1000,         # kg/mÂ³
    particle_size=0.005,  # 5mm
    color=(0.2, 0.5, 0.8)
)
```

**ì£¼ì˜ì‚¬í•­**:
- Sim2Real Gap ë§¤ìš° í¼ (ì•¡ì²´ ë¬¼ë¦¬ëŠ” ì‹œë®¬ ì–´ë ¤ì›€)
- Domain Randomization í•„ìˆ˜: ì ë„, ë°€ë„, flow rate ë³€í™”
- **ëŒ€ì•ˆ**: êµ¬ìŠ¬(beads)ë¡œ ë¨¼ì € ê²€ì¦, ë‚˜ì¤‘ì— ë¬¼

---

### 1.4 í‰ê°€ ë©”íŠ¸ë¦­

| ë©”íŠ¸ë¦­ | ì •ì˜ | ì¸¡ì • ë°©ë²• | ëª©í‘œì¹˜ |
|:---|:---|:---|:---:|
| **Success Rate** | ëª©í‘œëŸ‰ Â±10% ë„ë‹¬ | Vision: ì»µ ì±„ì›€ % ê³„ì‚° | >80% |
| **Spillage** | ìŸì€ ì•¡ì²´ ë¹„ìœ¨ | Vision: ì™¸ë¶€ ì•¡ì²´ í”½ì…€ ì¹´ìš´íŠ¸ | <5% |
| **Pouring Time** | ì‹œì‘~ë ì‹œê°„ | íƒ€ì´ë¨¸ | Adverb ìƒê´€ê´€ê³„ |
| **Smoothness** | Jerk í‘œì¤€í¸ì°¨ | ê´€ì ˆ ê°€ì†ë„ ë¡œê·¸ | <0.5 |
| **Level Accuracy** | ëª©í‘œ vs ì‹¤ì œ | Vision: mm ë‹¨ìœ„ | Â±5mm |

**Adverb Verification**:
```python
# "Slowly" vs "Quickly" ê²€ì¦
assert avg_tilt_speed["slowly"] < 0.3 * avg_tilt_speed["quickly"]
assert spillage["slowly"] < spillage["quickly"]
```

---

### 1.5 Dobot E6 êµ¬í˜„ ì‹¤í˜„ ê°€ëŠ¥ì„±

#### ì¥ì 
- âœ… í˜ì´ë¡œë“œ ì¶©ë¶„ (ì»µ + 250ml ë¬¼ = ~300g)
- âœ… ë°˜ë³µ ì •ë°€ë„ Â±0.1mmë¡œ Level ì œì–´ ê°€ëŠ¥
- âœ… Wrist camera ì¥ì°©ìœ¼ë¡œë¹„ì „ í”¼ë“œë°± ê°€ëŠ¥

#### ë‹¨ì 
- âŒ Force/Torque ì„¼ì„œ ì—†ìŒ â†’ ì•¡ì²´ ë¬´ê²Œ ë³€í™” ê°ì§€ ë¶ˆê°€
- âŒ ì ë„ ê³ ë ¤ ì–´ë ¤ì›€ (ì‹œê°ë§Œìœ¼ë¡œ ì œí•œì )
- âš ï¸ Isaac Sim fluid ì •í™•ë„ ë¬¸ì œ

#### ìš°íšŒ ì „ëµ
1. **êµ¬ìŠ¬(Beads) ë¨¼ì €**: Sim2Real Gap ê°ì†Œ, ë¬¼ë¦¬ ë‹¨ìˆœí™”
2. **Vision-only**: ì„¼ì„œ ì—†ì´ ë¹„ì „ë§Œìœ¼ë¡œ Level ì¶”ì •
3. **Pre-calibrated Profiles**: ë¬¼ íŠ¹ì • ì ë„ì— ëŒ€í•´ ë¯¸ë¦¬ ìµœì í™”

**ë‚œì´ë„ ì¬í‰ê°€**: â­â­â­â­ â†’ â­â­â­â­â­ (ë§¤ìš° ë„ì „ì , í•˜ì§€ë§Œ ê°€ëŠ¥)

---

## 2. Wiping Task ìƒì„¸ ë¶„ì„

### 2.1 ê¸°ì¡´ ì—°êµ¬ ì‚¬ë¡€

#### ì£¼ìš” ì—°êµ¬ í”„ë¡œì íŠ¸
| ì—°êµ¬ | ì ‘ê·¼ë²• | í•µì‹¬ ê¸°ìˆ  |
|:---|:---|:---|
| **Google Research** | Vision + RL | Visual observations â†’ Force control |
| **Adaptive Wiping (RL)** | Deep RL | ë‹¤ì–‘í•œ í‘œë©´ ê³¡ë¥ /ë§ˆì°° ì ì‘ |
| **Imitation Learning Wiping** | IL + FT Sensor | ì‚¬ëŒ ì‹œì—° â†’ Force profile í•™ìŠµ |
| **Deep Predictive Learning** | Teleoperation | ë¯¸ë˜ ì´ë¯¸ì§€ ì˜ˆì¸¡ + Impedance |

#### í•µì‹¬ ë°œê²¬
- âœ… **Contact-rich ëŒ€í‘œ íƒœìŠ¤í¬**: ë§ì€ ì—°êµ¬ê°€ ì§‘ì¤‘
- âœ… **Force Control í•„ìˆ˜**: Impedance, Admittance control í•„ìš”
- âœ… **Learning íš¨ê³¼ì **: RL/IL ëª¨ë‘ ì„±ê³µ ì‚¬ë¡€ å¤š
- âš ï¸ **F/T Sensor ì¤‘ìš”**: ëŒ€ë¶€ë¶„ Force-Torque ì„¼ì„œ ì‚¬ìš©

---

### 2.2 êµ¬í˜„ ë°©ë²•ë¡ 

#### A. Force Control Strategies

**1. Impedance Control**
```python
# End-effectorë¥¼ mass-spring-damperë¡œ ëª¨ë¸ë§
class ImpedanceController:
    def __init__(self, stiffness, damping):
        self.K = stiffness   # N/m
        self.D = damping     # Ns/m
    
    def compute_force(self, pos_error, vel_error):
        # F = K * Î”x + D * Î”v
        return self.K * pos_error + self.D * vel_error
```

**2. Variable Impedance** (Adverb ì ìš©!)
```python
adverb_impedance = {
    "gently": {"K": 50, "D": 10},   # ë‚®ì€ ê°•ì„± = ë¶€ë“œëŸ½ê²Œ
    "firmly": {"K": 200, "D": 50},  # ë†’ì€ ê°•ì„± = ê°•í•˜ê²Œ
}
```

**Dobot E6 ë¬¸ì œ**:
- âŒ F/T Sensor ì—†ìŒ â†’ Direct force measurement ë¶ˆê°€
- âœ… **Position-based Implicit Force**: ìœ„ì¹˜ë¡œ ì••ë ¥ ê°„ì ‘ ì œì–´

**ìš°íšŒ ë°©ë²•**:
```python
# Position-based force control (ì„¼ì„œ ì—†ì´)
def implicit_force_control(target_surface_height, compliance):
    # í…Œì´ë¸” í‘œë©´ë³´ë‹¤ ì•½ê°„ ì•„ë˜ë¡œ ëª©í‘œ ì„¤ì •
    target_z = surface_height - compliance  # compliance = 2mm
    # ë¡œë´‡ì´ í…Œì´ë¸”ê³¼ ì ‘ì´‰ â†’ ìì—°ìŠ¤ëŸ½ê²Œ ì••ë ¥ ë°œìƒ
    robot.move_to(x, y, target_z)
```

---

#### B. Perception

**1. Dirt/Spill Detection**
```python
# Vision-based ë¨¼ì§€ ê°ì§€
def detect_dirt(image):
    # Thresholdingìœ¼ë¡œ ë¨¼ì§€/ì˜¤ì—¼ í”½ì…€ ë¶„ë¦¬
    dirt_mask = (image < dirty_threshold)
    dirt_pixels = count(dirt_mask)
    clean_percentage = 1 - (dirt_pixels / total_pixels)
    return clean_percentage
```

**2. Surface Reconstruction**
- RGB-Dë¡œ í…Œì´ë¸” í‘œë©´ 3D ì¬êµ¬ì„±
- ë†’ì´ ë³€í™” ê°ì§€ â†’ Adaptive trajectory

---

### 2.3 Learning Approaches

#### Reinforcement Learning
- **Reward**: Clean percentage ì¦ê°€
- **State**: RGB image + Wiper position
- **Action**: Continuous wiping trajectory + Stiffness

#### Imitation Learning
- ì‚¬ëŒ Teleoperation ì‹œì—° ìˆ˜ì§‘
- Position + (Implicit) Force profile í•™ìŠµ
- Real-time adaptation with vision feedback

---

### 2.4 Isaac Sim êµ¬í˜„

#### Wiping í™˜ê²½ êµ¬ì„±
```python
# Isaac Sim wiping task
class WipingTask:
    def __init__(self):
        self.table = create_table(size=(0.8, 0.6))
        self.dirt = scatter_particles(num=100, area=0.3)
        self.wiper = attach_to_robot(shape="rect", size=(0.05, 0.03))
    
    def check_clean(self):
        # Dirt particlesì™€ wiper collision ì²´í¬
        cleaned = count_collisions(self.wiper, self.dirt)
        return cleaned / len(self.dirt)
```

**ì¥ì **:
- âœ… Contact physics ì‹œë®¬ ê°€ëŠ¥ (PhysX)
- âœ… Particle-based dirt representation
- âœ… Sim2Real Gapì´ Pouringë³´ë‹¤ ì‘ìŒ

---

### 2.5 í‰ê°€ ë©”íŠ¸ë¦­

| ë©”íŠ¸ë¦­ | ì •ì˜ | ì¸¡ì • ë°©ë²• | ëª©í‘œì¹˜ |
|:---|:---|:---|:---:|
| **Cleaning Rate** | ì œê±°ëœ ë¨¼ì§€ ë¹„ìœ¨ | Vision: Before/After í”½ì…€ ì°¨ì´ | >90% |
| **Wiping Time** | ì‘ì—… ì™„ë£Œ ì‹œê°„ | íƒ€ì´ë¨¸ | <30s |
| **Coverage** | Wiped ì˜ì—­ ë¹„ìœ¨ | Trajectory heatmap | >95% |
| **Force Consistency** | ì••ë ¥ ê· ì¼ì„± | Position variance (indirect) | Ïƒ < 2mm |
| **Collision Count** | ê³¼ë„í•œ ì¶©ëŒ | PhysX collision events | 0 |

---

### 2.6 Dobot E6 êµ¬í˜„ ì‹¤í˜„ ê°€ëŠ¥ì„±

#### ì¥ì 
- âœ… **Position-based control ê°€ëŠ¥**: F/T ì—†ì–´ë„ OK
- âœ… **Sim2Real Gap ì‘ìŒ**: Contact physicsê°€ ì•¡ì²´ë³´ë‹¤ ì•ˆì •ì 
- âœ… **Wiper ì œì‘ ì‰¬ì›€**: 3D í”„ë¦°íŒ… ë˜ëŠ” ìŠ¤í°ì§€ ë¶€ì°©

#### ë‹¨ì 
- âš ï¸ Force feedback ë¶€ì¡± â†’ ì••ë ¥ ì œì–´ ì •ë°€ë„ ë–¨ì–´ì§
- âš ï¸ í‘œë©´ ë†’ì´ ë³€í™” ê°ì§€ ì–´ë ¤ì›€ (Depth camera í•„ìš”)

#### êµ¬í˜„ ì „ëµ
1. **Fixed Surface**: í‰í‰í•œ í…Œì´ë¸”ë§Œ (ë†’ì´ ë³€í™” X)
2. **Vision-based Adaptation**: RGBë¡œ ë¨¼ì§€ ìœ„ì¹˜ íŒŒì•…
3. **Compliance via Soft Wiper**: ë¶€ë“œëŸ¬ìš´ ì¬ì§ˆë¡œ ì••ë ¥ ìì—° ë¶„ì‚°

**ë‚œì´ë„ ì¬í‰ê°€**: â­â­â­ â†’ â­â­â­ (Pouringë³´ë‹¤ ì‰¬ì›€)

---

## 3. ë‘ Task ë¹„êµ ì¢…í•©

### 3.1 ë¹„êµ í…Œì´ë¸”

| í•­ëª© | Pouring | Wiping |
|:---|:---|:---|
| **ê¸°ì¡´ ì—°êµ¬ ì„±ìˆ™ë„** | â­â­â­ | â­â­â­â­â­ (ë” ë§ìŒ) |
| **VLA ì ìš© ì‚¬ë¡€** | âœ… ìˆìŒ | âœ… ë§ìŒ |
| **Sim2Real Gap** | â­â­â­â­â­ (ë§¤ìš° í¼) | â­â­â­ (ì¤‘ê°„) |
| **Dobot E6 ì í•©ì„±** | âš ï¸ (ì„¼ì„œ ë¶€ì¡±) | âœ… (ì¶©ë¶„) |
| **êµ¬í˜„ ë‚œì´ë„** | â­â­â­â­â­ | â­â­â­ |
| **ì°¸ì‹ ì„±** | â­â­â­â­â­ | â­â­â­â­ |
| **Flow-matching í•„ìˆ˜ë„** | â­â­â­â­â­ | â­â­â­â­ |

### 3.2 ê¶Œì¥ì‚¬í•­

#### Option A: **Wiping ë¨¼ì €** (ì•ˆì „í•œ ì„ íƒ)
**ì´ìœ **:
- âœ… êµ¬í˜„ ìƒëŒ€ì ìœ¼ë¡œ ì‰¬ì›€
- âœ… Position-based controlë¡œ ì¶©ë¶„
- âœ… Sim2Real Gap ì‘ìŒ
- âœ… ë¹ ë¥¸ ì„±ê³¼ ê°€ëŠ¥

**ë¦¬ìŠ¤í¬**: ì°¸ì‹ ì„±ì´ Pouringë³´ë‹¤ ë‚®ìŒ

---

#### Option B: **Pouring ë„ì „** (High Risk High Return)
**ì´ìœ **:
- âœ… ê¸°ì¡´ VLAê°€ ê±°ì˜ ì•ˆ í•¨ (ì°¸ì‹ ì„± ìµœê³ )
- âœ… Flow-matchingì˜ ì§„ê°€ ë°œíœ˜
- âœ… ì„±ê³µ ì‹œ Top Conference í™•ì‹¤

**ë¦¬ìŠ¤í¬**:
- âŒ Isaac Sim fluid simulation ì–´ë ¤ì›€
- âŒ Sim2Real Gap í´ ê°€ëŠ¥ì„±
- âŒ ì‹œê°„ ë§ì´ ì†Œìš”

---

#### Option C: **Hybrid ì „ëµ** (ì¶”ì²œ â­â­â­â­â­)
1. **Phase 1**: Wiping ë¨¼ì € êµ¬í˜„ (2ì£¼)
   - Flow-matching pipeline ê²€ì¦
   - Dobot E6 ì œì–´ ìµìˆ™í•´ì§€ê¸°
   - **Deliverable**: Workshop paper

2. **Phase 2**: Pouring ë„ì „ (4ì£¼)
   - êµ¬ìŠ¬ë¡œ ì‹œì‘ â†’ ë¬¼ë¡œ í™•ì¥
   - Wiping ê²½í—˜ í™œìš©
   - **Deliverable**: Full Conference paper

---

## 4. ë‹¤ìŒ ë‹¨ê³„

### Immediate (ì´ë²ˆ ì£¼)
1. **Wiping Task í”„ë¡œí† íƒ€ì…**
   - Isaac Sim í™˜ê²½ êµ¬ì¶•
   - Dobot E6 + Wiper end-effector ëª¨ë¸
   - Simple dirt detection (particle-based)

2. **Pouring Feasibility Test**
   - Isaac Sim Particle System í…ŒìŠ¤íŠ¸
   - êµ¬ìŠ¬ pouring ì‹œë®¬ë ˆì´ì…˜
   - Sim2Real Gap ì‚¬ì „ í‰ê°€

### Short-term (2ì£¼)
1. Wiping Task ì™„ì„±
2. Pouringì€ ë³‘í–‰ ì—°êµ¬ (ë‚®ì€ ìš°ì„ ìˆœìœ„)

**ìµœì¢… ê²°ì • í•„ìš”**: Wiping ë¨¼ì € vs Pouring ë„ì „ vs Hybrid


---


# Motion VLA System Architecture & Data Pipeline

> **ì‘ì„±ì¼**: 2026-01-02  
> **ëª©ì **: Ï€0 ê¸°ë°˜ Motion VLAì˜ ì „ì²´ ì‹œìŠ¤í…œ íë¦„ê³¼ ë°ì´í„° íŒŒì´í”„ë¼ì¸ì„ ì‹œê°í™”í•˜ê³  ëª…ì„¸í™”

---

## System Overview

### ì „ì²´ ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨

```mermaid
graph TB
    subgraph Input
        I1[RGB Images<br/>224x224 or 384x384]
        I2[Text Instruction<br/>"Pick up cup carefully"]
        I3[Language Feedback<br/>"Move right" - Optional]
    end
    
    subgraph Stage1[Stage 1: Vision-Language Encoding]
        VL[PaliGemma / OpenVLA<br/>Vision-Language Encoder]
    end
    
    subgraph Stage2[Stage 2: Flow-matching Action Generation]
        FM[Flow-matching Expert<br/>ODE Integration]
        FM --> AC[Action Chunk<br/>shape: B x 10 x 7]
    end
    
    subgraph Stage3[Stage 3: Optional Corrections]
        RC[Residual Correction<br/>LGTC Task]
        SC[Style Controller<br/>ACMC Task]
    end
    
    subgraph Output
        O1[Final Actions<br/>6-DoF + Gripper]
        O2[Velocity/Accel Params<br/>Style-controlled]
    end
    
    I1 --> VL
    I2 --> VL
    VL -->|Embedding<br/>768-d| FM
    AC --> RC
    I3 -.->|If feedback| RC
    RC --> O1
    AC --> SC
    I2 -.->|Adverb extraction| SC
    SC --> O2
```

---

## Data Pipeline

### Training Data Flow

```mermaid
graph LR
    subgraph DataSources[Data Sources]
        D1[BridgeData V2]
        D2[OpenX Embodiment]
        D3[Isaac Sim<br/>Synthetic]
    end
    
    subgraph Preprocessing[Preprocessing Pipeline]
        P1[HDF5 Loader]
        P2[Image Resize<br/>+ Normalization]
        P3[Action Normalization]
        P4[Adverb Auto-Labeling]
    end
    
    subgraph Augmentation[Data Augmentation]
        A1[Trajectory Noise<br/>for LGTC]
        A2[Instruction Augmentation<br/>Add adverbs]
    end
    
    subgraph Batching[Batching]
        B1[Create Batches<br/>B x T x D]
    end
    
    D1 --> P1
    D2 --> P1
    D3 --> P1
    P1 --> P2
    P2 --> P3
    P3 --> P4
    P4 --> A1
    A1 --> A2
    A2 --> B1
    B1 --> Train[Training Loop]
```

---

## Component Specifications

### 1. Vision-Language Encoder

| í•­ëª© | ëª…ì„¸ |
|:---|:---|
| **Base Model** | PaliGemma-3B-pt-224 ë˜ëŠ” OpenVLA-7B |
| **Input** | RGB: (B, 3, 224, 224), Text: (B, seq_len) |
| **Output** | Embedding: (B, 768) or (B, 1024) |
| **Freeze** | Optional - ì´ˆê¸°ì—” freeze, Fine-tuning ì‹œ LoRA ì ìš© |

### 2. Flow-matching Action Expert

| í•­ëª© | ëª…ì„¸ |
|:---|:---|
| **Method** | Conditional Flow Matching (CFM) |
| **ODE Solver** | `torchdiffeq.odeint` |
| **Integration Steps** | 10-20 steps (inference time tradeoff) |
| **Output** | Action: (B, action_dim=7) ë˜ëŠ” Chunk: (B, 10, 7) |
| **Frequency** | 50Hz target (20ms per action) |

**ìˆ˜ì‹**:
- Velocity field: $v_\theta(\mathbf{a}_t, t, \mathbf{c})$
- Flow: $\mathbf{a}_1 = \mathbf{a}_0 + \int_0^1 v_\theta(\mathbf{a}_t, t, \mathbf{c}) dt$

### 3. Residual Correction Module (LGTC)

| í•­ëª© | ëª…ì„¸ |
|:---|:---|
| **Trigger** | Real-time language feedback ì…ë ¥ ì‹œ |
| **Input** | Base Action + CLIP/BERT Encoded Feedback |
| **Output** | Delta Action: (B, 7) |
| **Latency** | < 10ms (ì–¸ì–´ ì¸ì½”ë”© ì œì™¸) |

### 4. Style Controller (ACMC)

| í•­ëª© | ëª…ì„¸ |
|:---|:---|
| **Input** | Adverb Token (e.g., "carefully") |
| **Processing** | Dictionary lookup â†’ velocity/accel scaling |
| **Output** | Scaled Action + Dynamics Parameters |

---

## Inference Pipeline

### Deployment Architecture

```mermaid
sequenceDiagram
    participant User
    participant API as API Server<br/>(FastAPI)
    participant VL as VL Encoder
    participant FM as Flow Expert
    participant RC as Residual Head
    participant Robot
    
    User->>API: POST /predict<br/>{image, instruction}
    API->>VL: Encode multimodal input
    VL-->>API: Embedding (768-d)
    API->>FM: Generate action chunk
    FM-->>API: Base actions (10 steps)
    
    opt Language Feedback
        User->>API: POST /correct<br/>{"Move right"}
        API->>RC: Apply correction
        RC-->>API: Delta action
    end
    
    API-->>Robot: Send action @ 50Hz
    Robot-->>User: Execute motion
```

### API Endpoints

#### `/predict` (POST)
```json
{
  "image": "base64_encoded_image",
  "instruction": "Pick up the red cup carefully",
  "adverb": "carefully"  // Optional
}
```

**Response**:
```json
{
  "actions": [[x, y, z, rx, ry, rz, gripper], ...],  // 10-step chunk
  "velocity_scale": 0.5,
  "max_acceleration": 0.3
}
```

#### `/correct` (POST)
```json
{
  "feedback": "Move a bit to the right",
  "current_action": [x, y, z, rx, ry, rz, gripper]
}
```

**Response**:
```json
{
  "delta_action": [dx, dy, dz, drx, dry, drz, dg],
  "corrected_action": [new_x, new_y, ...]
}
```

---

## Training Strategy

### Pre-training Phase
1. **Dataset**: BridgeData V2 (~60K demos) + OpenX subset
2. **Objective**: Flow-matching Lossë§Œ í•™ìŠµ
3. **Duration**: ~3-5 days on 8x A100
4. **Checkpoint**: Save best model based on action MSE

### Fine-tuning Phase (Task-specific)

#### LGTC (Trajectory Correction)
1. **Dataset**: Isaac Sim Noisy + Corrected pairs (~10K episodes)
2. **Freeze**: VL Encoder, Flow Expert
3. **Train**: Residual Correction Headë§Œ
4. **Loss**: $\mathcal{L} = \|\Delta \mathbf{a}_{pred} - \Delta \mathbf{a}_{gt}\|^2$

#### ACMC (Adverb Control)
1. **Dataset**: BridgeData V2 + Auto-labeled adverbs
2. **Augmentation**: Instructionì— adverb ì¶”ê°€
3. **Loss**: Flow-matching Loss + Velocity consistency
4. **Metric**: Pearson correlation (adverb â†’ actual velocity)

---

## Performance Targets

| Metric | Target | Current (Baseline) |
|:---|:---:|:---:|
| **Inference Latency** | < 20ms per action | TBD |
| **Action Frequency** | 50Hz | TBD |
| **LGTC Success Rate** | > 80% | TBD |
| **ACMC Velocity Accuracy** | Correlation > 0.8 | TBD |
| **Model Size** | < 5GB (FP16) | ~3GB (PaliGemma-3B) |

---

## Directory Structure

```
motion-vla/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ motion_vla/
â”‚       â”œâ”€â”€ models/
â”‚       â”‚   â”œâ”€â”€ vl_encoder.py          # Stage 1
â”‚       â”‚   â”œâ”€â”€ flow_action_expert.py  # Stage 2
â”‚       â”‚   â”œâ”€â”€ residual_head.py       # Stage 3 (LGTC)
â”‚       â”‚   â””â”€â”€ style_controller.py    # Stage 3 (ACMC)
â”‚       â”œâ”€â”€ data/
â”‚       â”‚   â”œâ”€â”€ hdf5_loader.py
â”‚       â”‚   â””â”€â”€ adverb_labeler.py
â”‚       â”œâ”€â”€ training/
â”‚       â”‚   â”œâ”€â”€ train_flow.py
â”‚       â”‚   â””â”€â”€ train_residual.py
â”‚       â””â”€â”€ inference/
â”‚           â””â”€â”€ api_server.py
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ generate_noisy_traj.py
â”‚   â””â”€â”€ evaluate_lgtc.py
â””â”€â”€ configs/
    â”œâ”€â”€ paligemma_config.yaml
    â””â”€â”€ training_config.yaml
```


---


# VLA Research Trend & Gap Analysis

## 1. ìµœì‹  VLA ëª¨ë¸ ë™í–¥ (State-of-the-Art)
ìµœê·¼ Vision-Language-Action (VLA) ëª¨ë¸ë“¤ì€ RT-2(Google), OpenVLA(Stanford), Octo(Berkeley) ë“±ì„ ì¤‘ì‹¬ìœ¼ë¡œ ë°œì „í•˜ê³  ìˆìœ¼ë©°, ì£¼ë¡œ **"Generalist Policy"** (ë‹¤ì–‘í•œ ë¡œë´‡/íƒœìŠ¤í¬ë¥¼ í•˜ë‚˜ì˜ ëª¨ë¸ë¡œ ìˆ˜í–‰)ì— ì§‘ì¤‘í•˜ê³  ìˆìŠµë‹ˆë‹¤.

| ëª¨ë¸ | íŠ¹ì§• | Action Space | ì£¼ìš” í•œê³„ì  |
| :--- | :--- | :--- | :--- |
| **RT-2** | VLM(PaLM-E ë“±)ì„ ë¡œë´‡ ë°ì´í„°ë¡œ Fine-tuning | Discrete (Tokens) | ì¶”ë¡  ì†ë„ê°€ ëŠë¦¼(1-3Hz), ì •ë°€ ì œì–´ ë¶€ì¡± |
| **OpenVLA** | Llama 2 + SigLIP ê¸°ë°˜, ì˜¤í”ˆì†ŒìŠ¤ SOTA | Discrete (Tokens) | Action Tokenizationìœ¼ë¡œ ì¸í•œ ë™ì‘ ëŠê¹€(Jittering) |
| **Octo** | Diffusion Policy ê¸°ë°˜ì˜ Generalist ëª¨ë¸ | Continuous | ê³„ì‚° ë¹„ìš©ì´ ë§¤ìš° ë†’ìŒ, ì–¸ì–´ ì´í•´ë„(Reasoning)ëŠ” LLMë³´ë‹¤ ë‚®ìŒ |

## 2. ì£¼ìš” ê¸°ìˆ ì  í•œê³„ (Research Gaps)

### A. **Fine-grained Control & Motion Quality** (ì •ë°€ ì œì–´ ë° ëª¨ì…˜ í’ˆì§ˆ)
ëŒ€ë¶€ë¶„ì˜ VLA ëª¨ë¸ì€ Actionì„ 0~255 ì‚¬ì´ì˜ **ì´ì‚°í™”ëœ í† í°(Discretized Tokens)**ìœ¼ë¡œ ì˜ˆì¸¡í•©ë‹ˆë‹¤.
- **ë¬¸ì œì **: ì´ë¡œ ì¸í•´ ë¡œë´‡ì˜ ì›€ì§ì„ì´ ëšëš ëŠê¸°ê±°ë‚˜(Stuttering), ì •ë°€í•œ ì¡°ì‘(ë°”ëŠ˜ ê¿°ê¸°, ì•¡ì²´ ë”°ë¥´ê¸° ë“±)ì—ì„œ ì„±ëŠ¥ì´ ì €í•˜ë©ë‹ˆë‹¤.
- **ê¸°ì¡´ í•´ê²°ì±…**: Diffusion Policy ë“±ì„ ì‚¬ìš©í•˜ì§€ë§Œ, ì´ëŠ” ì—°ì‚°ëŸ‰ì´ ë§ì•„ ì‹¤ì‹œê°„(Real-time) ë°˜ì‘ì„±ì´ ë–¨ì–´ì§€ëŠ” Trade-offê°€ ìˆìŠµë‹ˆë‹¤.

### B. **Frequency & Real-time Interaction** (ì‹¤ì‹œê°„ì„±)
ê±°ëŒ€ ì–¸ì–´ ëª¨ë¸(LLM) ê¸°ë°˜ VLAëŠ” ì¶”ë¡  ì†ë„ê°€ ëŠë ¤(3~5Hz), ê³ ì† ì œì–´ë‚˜ ì¸ê°„ê³¼ì˜ ì‹¤ì‹œê°„ ìƒí˜¸ì‘ìš©(Human-Robot Interaction)ì— ì·¨ì•½í•©ë‹ˆë‹¤.
- **Gap**: ì‹¤í–‰ ë„ì¤‘ ì‚¬ëŒì˜ ê°œì…("ì ê¹ ë©ˆì¶°", "ì¡°ê¸ˆ ë” ì™¼ìª½ìœ¼ë¡œ")ì— ì¦‰ê° ë°˜ì‘í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤.

### C. **Adverbial Instruction Understanding** (ë¶€ì‚¬ì  ì§€ì‹œ ì´í•´ ë¶€ì¬)
í˜„ì¬ VLAëŠ” "Pick up the cup" ê°™ì€ **What(ë¬´ì—‡ì„)**ì— ì§‘ì¤‘í•©ë‹ˆë‹¤.
- **Gap**: "Pick up the cup **carefully**" ë˜ëŠ” "**quickly**"ì™€ ê°™ì´ **How(ì–´ë–»ê²Œ)** ë™ì‘í•´ì•¼ í•˜ëŠ”ì§€ì— ëŒ€í•œ ì—°êµ¬ëŠ” ê±°ì˜ ì—†ìŠµë‹ˆë‹¤. (Motion Style Transfer ë¶€ì¬)

## 3. Motion VLAê°€ ì§‘ì¤‘í•´ì•¼ í•  ì˜ì—­ (Niche)
ìœ„ ë¶„ì„ì„ ë°”íƒ•ìœ¼ë¡œ ìš°ë¦¬ í”„ë¡œì íŠ¸(`Motion VLA`)ëŠ” ë‹¤ìŒ ì˜ì—­ì„ ê³µëµí•´ì•¼ í•©ë‹ˆë‹¤.

1.  **Language-Guided Trajectory Adaptation**: ì´ˆê¸° ê³„íšëœ ê²½ë¡œë¥¼ ì–¸ì–´ í”¼ë“œë°±ìœ¼ë¡œ **ì‹¤ì‹œê°„ ìˆ˜ì •**í•˜ëŠ” ëŠ¥ë ¥.
2.  **Adverb-Conditioned Control**: "ì²œì²œíˆ", "ì¡°ì‹¬ìŠ¤ëŸ½ê²Œ" ë“±ì˜ ë¶€ì‚¬ë¥¼ **Joint Velocity/Acceleration ë˜ëŠ” Stiffness** ì œì–´ë¡œ ë§¤í•‘í•˜ëŠ” ëŠ¥ë ¥.
3.  **Residual Policy Learning**: ë¬´ê±°ìš´ VLAê°€ High-level Goal(ì›¨ì´í¬ì¸íŠ¸)ë§Œ ì£¼ê³ , ê°€ë²¼ìš´ Motion Policyê°€ Low-level ì œì–´ë¥¼ ë‹´ë‹¹í•˜ì—¬ **ì†ë„ì™€ ì§€ëŠ¥ì„ ëª¨ë‘ ì¡ëŠ” êµ¬ì¡°**.


---


# Deep Dive: Language-Guided Trajectory Correction & Motion Style Control

## Background
VLA ëª¨ë¸ì˜ í•œê³„(discrete tokenizationìœ¼ë¡œ ì¸í•œ jittering, ì‹¤ì‹œê°„ ë°˜ì‘ì„± ë¶€ì¡±)ë¥¼ ê·¹ë³µí•˜ë ¤ë©´, ê¸°ì¡´ ì—°êµ¬ì—ì„œ ì´ë¯¸ ê²€ì¦ëœ ë°©ë²•ë¡ ì„ í™œìš©í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤. ë³¸ ë¬¸ì„œëŠ” ì›¹ ì¡°ì‚¬ë¥¼ í†µí•´ ë°œê²¬í•œ **ê´€ë ¨ ì„ í–‰ ì—°êµ¬**ì™€ **êµ¬í˜„ ê°€ëŠ¥í•œ ì ‘ê·¼ë²•**ì„ ì‹¬ì¸µ ë¶„ì„í•©ë‹ˆë‹¤.

---

## Analysis: Task 1 - Language-Guided Trajectory Correction

### 1.1 ì£¼ìš” ê´€ë ¨ ë…¼ë¬¸/í”„ë ˆì„ì›Œí¬
| ë…¼ë¬¸/í”„ë¡œì íŠ¸ | í•µì‹¬ ì•„ì´ë””ì–´ | ë°©ë²•ë¡  | ì ìš© ê°€ëŠ¥ì„± |
| :--- | :--- | :--- | :--- |
| **ExTraCT** (Frontiers in Robotics, 2023) | LLMì„ ì´ìš©í•´ ìì—°ì–´ í”¼ë“œë°±ì„ ê¶¤ì  ìˆ˜ì • í•¨ìˆ˜ë¡œ ë³€í™˜ | Modular êµ¬ì¡°: Language Understanding + Trajectory Adapter | â­â­â­â­â­ ì§ì ‘ ì ìš© ê°€ëŠ¥ |
| **Iterative Residual Policy (IRP)** (RSS) | Delta dynamicsë¥¼ í•™ìŠµí•˜ì—¬ ê¸°ì¡´ ê¶¤ì ì„ ì ì§„ì ìœ¼ë¡œ ê°œì„  | Model-based RL: $\Delta q = f(q_{prev}, g_{target})$ | â­â­â­â­â­ ìš°ë¦¬ Residual ê°œë…ê³¼ ì™„ë²½íˆ ì¼ì¹˜ |
| **Diffusion Trajectory-guided Policy** (arXiv) | Vision-Language Modelë¡œ Diffusion ê¸°ë°˜ ê¶¤ì  ìƒì„± í›„ Policy ê°€ì´ë“œ | Generative model + Policy distillation | â­â­â­ ê³„ì‚° ë¹„ìš© ë†’ìŒ, ì´ˆê¸°ì—” IRP ìš°ì„  |

### 1.2 ì„ íƒí•œ êµ¬í˜„ ì „ëµ: **IRP (Iterative Residual Policy)**
- **ì„ ì • ì´ìœ **:
    1.  ìš°ë¦¬ê°€ ì œì•ˆí•œ "Residual Action ($\Delta q$)" ê°œë…ê³¼ ì´ë¡ ì ìœ¼ë¡œ ì •í™•íˆ ì¼ì¹˜í•©ë‹ˆë‹¤.
    2.  ê¸°ì¡´ Oracle/Nominal Policy ìœ„ì— Correction Layerë§Œ í•™ìŠµí•˜ë©´ ë˜ë¯€ë¡œ ë°ì´í„° íš¨ìœ¨ì ì…ë‹ˆë‹¤.
    3.  Fine-tuningì´ ì•„ë‹Œ **Add-on Module** í˜•íƒœë¼ì„œ OpenVLA ê°™ì€ ê±°ëŒ€ ëª¨ë¸ì„ ê±´ë“œë¦¬ì§€ ì•Šì•„ë„ ë©ë‹ˆë‹¤.

- **êµ¬ì²´ì  êµ¬í˜„ ë°©ì•ˆ**:
    ```python
    # ì˜ì‚¬ ì½”ë“œ (Pseudo-code)
    class ResidualCorrectionHead(nn.Module):
        """
        ì…ë ¥: í˜„ì¬ ê´€ì¸¡(Obs), ì–¸ì–´ í”¼ë“œë°±(Lang), ì´ì „ ê¶¤ì (History)
        ì¶œë ¥: Delta Action (Î”q)
        """
        def forward(self, obs, lang_correction, traj_history):
            # 1. VLMìœ¼ë¡œ ì–¸ì–´ ì¸ì½”ë”©
            lang_embed = self.vlm_encoder(lang_correction)  # "ì˜¤ë¥¸ìª½ìœ¼ë¡œ" -> [768,]
            
            # 2. ê¶¤ì  íˆìŠ¤í† ë¦¬ ì¸ì½”ë”© (Temporal Transformer)
            traj_embed = self.temporal_encoder(traj_history)  # (T, D) -> [512,]
            
            # 3. Fusion + Residual Prediction
            fused = torch.cat([obs, lang_embed, traj_embed], dim=-1)
            delta_action = self.mlp(fused)  # [D_action]
            return delta_action
    ```

### 1.3 ë°ì´í„° ìˆ˜ì§‘ ì „ëµ (IRP ë…¼ë¬¸ ê¸°ë°˜)
IRP ë…¼ë¬¸ì€ "Noisy Trajectory"ë¥¼ ìƒì„±í•˜ê³  ì´ë¥¼ ë³µêµ¬í•˜ëŠ” ê³¼ì •ì„ ìë™ìœ¼ë¡œ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤.
- **ìš°ë¦¬ ì ìš©ì•ˆ**:
    1.  Isaac Simì—ì„œ ì„±ê³µ ê¶¤ì  $\tau_{success}$ ìƒì„±.
    2.  ì¤‘ê°„ ìŠ¤í…ì— Gaussian Noise ì£¼ì… -> $\tau_{noisy}$.
    3.  Correction Controller(ì˜ˆ: MPC)ê°€ ë³µêµ¬ -> $\tau_{corrected}$.
    4.  Noise ë°©í–¥ì„ ë¶„ì„í•˜ì—¬ ìë™ìœ¼ë¡œ ì–¸ì–´ ë¼ë²¨ ìƒì„± (ì˜ˆ: $\Delta x > 0$ â†’ "ì™¼ìª½ìœ¼ë¡œ", $\Delta z > 0$ â†’ "ìœ„ë¡œ").

---

## Analysis: Task 2 - Adverb-Conditioned Motion Control

### 2.1 ì£¼ìš” ê´€ë ¨ ì—°êµ¬
| ì—°êµ¬ | í•µì‹¬ ê¸°ë²• | ë¬¼ë¦¬ì  ë§¤í•‘ | ì ìš© ê°€ëŠ¥ì„± |
| :--- | :--- | :--- | :--- |
| **Language-to-Velocity Control** (arXiv, CMU) | Adverbë¥¼ ì†ë„/ê°€ì†ë„ ì œì•½ ì¡°ê±´ìœ¼ë¡œ í•´ì„ | "Slowly" â†’ $v_{max} = 0.3 \cdot v_{nominal}$ | â­â­â­â­â­ ì¦‰ì‹œ êµ¬í˜„ ê°€ëŠ¥ |
| **Verb-Adverb Motion Style** (Dartmouth) | Verb(ë™ì‘) + Adverb(ìŠ¤íƒ€ì¼)ì„ ë¶„ë¦¬í•˜ì—¬ Interpolation | Style Latent Space í•™ìŠµ | â­â­â­ ì—°êµ¬ì  ê°€ì¹˜ ë†’ìœ¼ë‚˜ ë³µì¡í•¨ |
| **MotionGlot** (Brown Univ.) | Motionì„ ì–¸ì–´ì²˜ëŸ¼ ì·¨ê¸‰, Tokenizeí•˜ì—¬ ë³€í™˜ | Seq2Seq Transformer | â­â­ ìš°ë¦¬ ëª©ì ê³¼ëŠ” ë‹¤ì†Œ ê±°ë¦¬ ìˆìŒ |

### 2.2 ì„ íƒí•œ êµ¬í˜„ ì „ëµ: **Language-to-Velocity Constraint Mapping**
- **ì„ ì • ì´ìœ **:
    1.  ê°€ì¥ ì§ê´€ì ì´ê³  ë¬¼ë¦¬ì ìœ¼ë¡œ í•´ì„ ê°€ëŠ¥í•©ë‹ˆë‹¤.
    2.  ê¸°ì¡´ ë°ì´í„°ì— "Post-processing"ì„ í†µí•´ Adverbë¥¼ ìë™ ë¼ë²¨ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    3.  VLA ì¶œë ¥ì— **ë³„ë„ì˜ Style Token**ì„ ì¶”ê°€í•˜ë©´ ë©ë‹ˆë‹¤.

- **êµ¬í˜„ ì˜ˆì‹œ**:
    ```python
    # Adverb -> Dynamics Parameter ë§¤í•‘
    ADVERB_MAPPING = {
        "carefully": {"v_scale": 0.5, "a_max": 0.3, "jerk_limit": 0.1},
        "quickly":   {"v_scale": 1.5, "a_max": 2.0, "jerk_limit": 1.0},
        "steadily":  {"v_scale": 0.8, "a_max": 0.5, "jerk_limit": 0.05},
    }
    
    def apply_adverb_style(trajectory, adverb):
        """ì£¼ì–´ì§„ ê¶¤ì ì— ë¶€ì‚¬ ìŠ¤íƒ€ì¼ì„ ì ìš©"""
        params = ADVERB_MAPPING[adverb]
        # ì†ë„ ìŠ¤ì¼€ì¼ë§
        trajectory.velocity *= params["v_scale"]
        # ê°€ì†ë„ í´ë¦¬í•‘
        trajectory.acceleration = np.clip(
            trajectory.acceleration, 
            -params["a_max"], 
            params["a_max"]
        )
        return trajectory
    ```

### 2.3 ìë™ ë¼ë²¨ë§ ì „ëµ
ê¸°ì¡´ BridgeData V2, OpenX ë“±ì˜ ë°ì´í„°ì…‹ì—ëŠ” Adverb ë¼ë²¨ì´ ì—†ìŠµë‹ˆë‹¤. ìë™ ìƒì„± ë°©ì•ˆ:
1.  **ì†ë„ ê¸°ë°˜ ë¶„ë¥˜**:
    - í‰ê·  ì†ë„ $< 0.1$ m/s â†’ "slowly"
    - í‰ê·  ì†ë„ $> 0.5$ m/s â†’ "quickly"
2.  **Jerk(ê°€ì†ë„ ë³€í™”ìœ¨) ê¸°ë°˜**:
    - Jerk í‘œì¤€í¸ì°¨ $< 0.05$ â†’ "steadily"
    - Jerk í‘œì¤€í¸ì°¨ $> 0.2$ â†’ "roughly"
3.  **Instruction Augmentation**:
    - ì›ë³¸: "Pick up the cup"
    - ì¦ê°•: "Pick up the cup **carefully**" (ìë™ ë¶„ë¥˜ëœ ìŠ¤íƒ€ì¼ ë¶€ì‚¬ ì¶”ê°€)

---

## Findings

### í•µì‹¬ ë°œê²¬ì‚¬í•­
1.  **IRPëŠ” ìš°ë¦¬ Task 1ì˜ Perfect Matchì…ë‹ˆë‹¤**: Delta Dynamics í•™ìŠµ ë°©ì‹ì´ Residual Policyì™€ ë™ì¼í•˜ë©°, ë…¼ë¬¸ì—ì„œ ì´ë¯¸ noisy trajectory ë³µêµ¬ ì‹¤í—˜ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤.
2.  **Adverb-to-Velocity Mappingì€ ê²€ì¦ëœ ì ‘ê·¼ë²•ì…ë‹ˆë‹¤**: CMU ì—°êµ¬ì—ì„œ ì´ë¯¸ "slowly", "gently" ë“±ì„ ì†ë„ ì œì•½ìœ¼ë¡œ ë§¤í•‘í•˜ì—¬ ì„±ê³µí–ˆìŠµë‹ˆë‹¤.
3.  **Human-in-the-loop ë°ì´í„°ëŠ” ë“œë­…ë‹ˆë‹¤**: ëŒ€ë¶€ë¶„ ì—°êµ¬ê°€ ì‹œë®¬ë ˆì´ì…˜ ìë™ ìƒì„± ë˜ëŠ” Augmentationì— ì˜ì¡´í•˜ê³  ìˆì–´, ìš°ë¦¬ë„ Isaac Sim + Auto-labeling ì „ëµì´ íƒ€ë‹¹í•©ë‹ˆë‹¤.

### êµ¬í˜„ ìš°ì„ ìˆœìœ„
| ìš°ì„ ìˆœìœ„ | í•­ëª© | ì˜ˆìƒ ì†Œìš” ì‹œê°„ | ê·¼ê±° |
| :---: | :--- | :--- | :--- |
| **P0** | IRP ê¸°ë°˜ Residual Correction Head êµ¬í˜„ | 1-2ì£¼ | í•µì‹¬ ì°¨ë³„í™” ìš”ì†Œ, ë…¼ë¬¸ ë ˆí¼ëŸ°ìŠ¤ ëª…í™• |
| **P1** | Adverb Mapping + Auto-labeling íŒŒì´í”„ë¼ì¸ | 1ì£¼ | ë°ì´í„° ì¦ê°•ì˜ í•µì‹¬, êµ¬í˜„ ë‚œì´ë„ ë‚®ìŒ |
| **P2** | Isaac Sim í™˜ê²½ êµ¬ì¶• ë° Noisy Traj ìƒì„± | 2ì£¼ | ë°ì´í„° ì¸í”„ë¼, ë³‘ë ¬ ì²˜ë¦¬ ê°€ëŠ¥ |

---

## Conclusion

### ë‹¤ìŒ ë‹¨ê³„ (Next Actions)
1.  **[ë¬¸ì„œí™”]** IRP ë…¼ë¬¸ ì •ë… í›„ `docs/irp_paper_review.md` ì‘ì„± (ìˆ˜ì‹ ë° ì•Œê³ ë¦¬ì¦˜ ì •ë¦¬).
2.  **[ì½”ë“œ]** `src/motion_vla/residual_head.py` êµ¬í˜„ ì‹œì‘ (IRP ê¸°ë°˜ ì•„í‚¤í…ì²˜).
3.  **[ì‹¤í—˜]** BridgeData V2 ì¼ë¶€ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ì†ë„ ê¸°ë°˜ Adverb Auto-labeling ìŠ¤í¬ë¦½íŠ¸ ì‘ì„± ë° ê²€ì¦.

### ì°¸ê³  ë¬¸í—Œ
- ExTraCT: [Frontiers in Robotics and AI, 2023](https://www.frontiersin.org/articles/...)
- IRP (Iterative Residual Policy): [Robotics: Science and Systems](https://roboticsproceedings.org/...)
- Language-to-Velocity Mapping: [arXiv, CMU](https://arxiv.org/...)


---


# IRP (Iterative Residual Policy) ë…¼ë¬¸ ìš”ì•½

> **ì‘ì„±ì¼**: 2026-01-02  
> **ì¶œì²˜**: Robotics: Science and Systems (RSS)  
> **ë…¼ë¬¸ ì œëª©**: Iterative Residual Policy: Learning to Correct Policy Predictions  

## Background
ê¸°ì¡´ ë¡œë´‡ ì œì–´ ë°©ì‹ì€ "ì™„ë²½í•œ Policy"ë¥¼ ì²˜ìŒë¶€í„° í•™ìŠµí•˜ë ¤ í–ˆìœ¼ë‚˜, ì´ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤:
- ìƒ˜í”Œ ë¹„íš¨ìœ¨ì„±: ì™„ë²½í•œ ì •ì±… í•™ìŠµì— ìˆ˜ë§Œ~ìˆ˜ì‹­ë§Œ episodes í•„ìš”.
- Generalization ë¶€ì¡±: í•™ìŠµ ë‹¹ì‹œ ë³´ì§€ ëª»í•œ ë¬¼ì²´/í™˜ê²½ì—ì„œ ì‹¤íŒ¨.
- Catastrophic Forgetting: Fine-tuning ì‹œ ì´ì „ ì§€ì‹ ìƒì‹¤.

IRPëŠ” ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ **"ê¸°ì¡´ Policy(Nominal Policy)ì˜ ì‹¤ìˆ˜ë¥¼ ìˆ˜ì •í•˜ëŠ” Residual Policy"**ë¥¼ í•™ìŠµí•©ë‹ˆë‹¤.

---

## Analysis: í•µì‹¬ ì•Œê³ ë¦¬ì¦˜

### ìˆ˜ì‹ ì •ì˜
1.  **Nominal Policy**: ì´ˆê¸° ì •ì±… $\pi_0(a|s)$ (ì˜ˆ: Pre-trained VLA, Heuristic Controller)
2.  **Residual Policy**: $\pi_R(\Delta a | s, \tau_{history})$ â†’ "ìˆ˜ì •ëŸ‰"ë§Œ ì˜ˆì¸¡
3.  **ìµœì¢… Action**: $a_{final} = a_0 + \Delta a$

### í•™ìŠµ ë°©ì‹
IRPëŠ” ë‹¤ìŒê³¼ ê°™ì€ **Delta Dynamics Model**ì„ í•™ìŠµí•©ë‹ˆë‹¤:
$$
s_{t+1} = f(s_t, a_0 + \Delta a) \approx s_t + \Delta s
$$

ì—¬ê¸°ì„œ $\Delta s$ëŠ” "ì‘ì€ ìˆ˜ì •ì´ ìƒíƒœì— ë¯¸ì¹˜ëŠ” ì˜í–¥"ì´ë©°, ì´ë¥¼ ë°˜ë³µì ìœ¼ë¡œ ì ìš©í•˜ì—¬ ëª©í‘œ ìƒíƒœ $s_{goal}$ì— ë„ë‹¬í•©ë‹ˆë‹¤.

**ì•Œê³ ë¦¬ì¦˜ ì˜ì‚¬ì½”ë“œ**:
```python
# IRP í•™ìŠµ ë‹¨ê³„
for episode in range(num_episodes):
    # 1. Nominal Policyë¡œ ì´ˆê¸° ê¶¤ì  ìƒì„±
    traj_nominal = rollout(pi_0, env)
    
    # 2. ëª©í‘œì™€ì˜ ì°¨ì´ ê³„ì‚°
    delta_goal = goal_state - traj_nominal[-1]
    
    # 3. Residual Policyë¡œ ìˆ˜ì •ëŸ‰ ì˜ˆì¸¡
    for t in range(T):
        delta_a = pi_R(obs[t], delta_goal, traj_nominal[:t])
        action[t] = nominal_action[t] + delta_a
    
    # 4. ìƒˆë¡œìš´ ê¶¤ì ìœ¼ë¡œ í•™ìŠµ
    traj_corrected = rollout_with_actions(env, action)
    loss = MSE(traj_corrected[-1], goal_state)
    update(pi_R, loss)
```

---

## Findings

### ìš°ë¦¬ í”„ë¡œì íŠ¸ ì ìš© ì‹œ ì¥ì 
1.  **ë°ì´í„° íš¨ìœ¨ì„±**: Nominal Policy(ì˜ˆ: OpenVLA)ê°€ "ëŒ€ëµì ì¸" ë™ì‘ë§Œ ìˆ˜í–‰í•˜ê³ , Residual Headê°€ "ì–¸ì–´ í”¼ë“œë°± ê¸°ë°˜ ë¯¸ì„¸ ì¡°ì •"ë§Œ ë‹´ë‹¹í•˜ë¯€ë¡œ ì ì€ ë°ì´í„°ë¡œ í•™ìŠµ ê°€ëŠ¥.
2.  **ëª¨ë“ˆí™”**: OpenVLA ì „ì²´ë¥¼ Fine-tuningí•˜ì§€ ì•Šê³  Residual Headë§Œ ì¶”ê°€í•˜ë©´ ë˜ë¯€ë¡œ VRAM íš¨ìœ¨ì .
3.  **ì‹¤ì‹œê°„ Correction**: Iterativeí•˜ê²Œ ìˆ˜ì •ëŸ‰ì„ ëˆ„ì  ì ìš©í•˜ë¯€ë¡œ, "ì˜¤ë¥¸ìª½ìœ¼ë¡œ" ê°™ì€ í”¼ë“œë°±ì„ ì—¬ëŸ¬ ë²ˆ ë°˜ì˜ ê°€ëŠ¥.

### ìš°ë¦¬ê°€ ì¶”ê°€ë¡œ í•´ì•¼ í•  ê²ƒ
- **Language Grounding**: ì›ë³¸ IRPëŠ” Goal State $s_{goal}$ì„ ì§ì ‘ ì£¼ì§€ë§Œ, ìš°ë¦¬ëŠ” "ì˜¤ë¥¸ìª½ìœ¼ë¡œ"ê°™ì€ **ì–¸ì–´**ë¥¼ $\Delta goal$ ë²¡í„°ë¡œ ë³€í™˜í•´ì•¼ í•©ë‹ˆë‹¤.
    - í•´ê²°ì±…: CLIP/BERTë¡œ ì–¸ì–´ ì„ë² ë”© í›„, MLPë¡œ Target Delta ì˜ˆì¸¡.

---

## Conclusion

IRPëŠ” ìš°ë¦¬ Task 1(Language-Guided Trajectory Correction)ì˜ **ì´ë¡ ì  ê¸°ë°˜**ìœ¼ë¡œ ì™„ë²½í•˜ê²Œ ì ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤. ë‹¤ìŒ ë‹¨ê³„ë¡œ `ResidualCorrectionHead` êµ¬í˜„ì„ ì‹œì‘í•˜ê³ , Isaac Simì—ì„œ Nominal + Residual êµ¬ì¡°ë¥¼ ê²€ì¦í•´ì•¼ í•©ë‹ˆë‹¤.

### ì°¸ê³  êµ¬í˜„ ë ˆí¬ì§€í† ë¦¬
- [IRP Official Code (ì¶”ì •)](https://github.com/.../irp) â† ì‹¤ì œ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ í•„ìš”
- ëŒ€ì•ˆ: ì§ì ‘ ë…¼ë¬¸ ìˆ˜ì‹ ê¸°ë°˜ êµ¬í˜„ (`src/motion_vla/models/residual_head.py`)


---


# New VLA Task Proposals

ê¸°ì¡´ VLA ì—°êµ¬ì˜ í•œê³„(ì •ë°€ ì œì–´, ìŠ¤íƒ€ì¼ ë¶€ì¬)ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´, ë‹¤ìŒê³¼ ê°™ì€ **Motion ì¤‘ì‹¬ì˜ ì‹ ê·œ íƒœìŠ¤í¬ 2ê°€ì§€**ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.

---

## Task 1: Language-Guided Trajectory Correction (LGTC)
### 1. ì •ì˜ (Definition)
ë¡œë´‡ì´ ë™ì‘ì„ ìˆ˜í–‰í•˜ëŠ” ë„ì¤‘(On-the-fly), ì¸ê°„ì˜ ì–¸ì–´ì  í”¼ë“œë°±ì„ ë°›ì•„ **ì‹¤ì‹œê°„ìœ¼ë¡œ ê¶¤ì (Trajectory)ì„ ìˆ˜ì •**í•˜ëŠ” íƒœìŠ¤í¬ì…ë‹ˆë‹¤.
> ì˜ˆì‹œ: ë¡œë´‡ì´ ë¬¼ê±´ì„ ì§‘ìœ¼ëŸ¬ ê°ˆ ë•Œ "ì¡°ê¸ˆ ë” ì˜¤ë¥¸ìª½ìœ¼ë¡œ"ë¼ê³  ë§í•˜ë©´, í˜„ì¬ ê¶¤ì ì—ì„œ ì¦‰ì‹œ ì˜¤ë¥¸ìª½ìœ¼ë¡œ í¸í–¥ëœ ìƒˆë¡œìš´ ê¶¤ì ì„ ìƒì„±í•´ì•¼ í•¨.

### 2. ì…/ì¶œë ¥ (Input/Output)
- **Input**:
    - Current Observation (RGB Image + Proprioception)
    - Instruction (Initial: "Cupì„ ì§‘ì–´ë¼", Feedback: "ë” ì˜¤ë¥¸ìª½ìœ¼ë¡œ")
    - History (ì§€ë‚œ $T$ ìŠ¤í…ì˜ joint positions)
- **Output**:
    - Delta Action ($\Delta q$): í˜„ì¬ ê³„íšëœ ê¶¤ì  ëŒ€ë¹„ ìˆ˜ì •ëŸ‰ (Residual Action)

### 3. ë°ì´í„°ì…‹ ìš”êµ¬ì‚¬í•­ (Data Requirements)
- **ê¸°ì¡´ ë°ì´í„°ì…‹(BridgeData V2, OpenX) í™œìš© ë¶ˆê°€**: ëŒ€ë¶€ë¶„ ì„±ê³µ ê¶¤ì ë§Œ ì¡´ì¬í•˜ë©°, "ìˆ˜ì •(Correction)" ë°ì´í„°ê°€ ì—†ìŒ.
- **ìˆ˜ì§‘ ì „ëµ**:
    1.  **Simulation (Isaac Gym/Sim)**: ì •ìƒ ê¶¤ì ì— ë…¸ì´ì¦ˆë¥¼ ì£¼ì–´ ì‹¤íŒ¨í•˜ê²Œ ë§Œë“  í›„, ì´ë¥¼ ë³µêµ¬(Correction)í•˜ëŠ” ê¶¤ì ì„ ìƒì„±í•˜ê³ , í•´ë‹¹ ìˆ˜ì • ì¡°ì‘ì— ë§ëŠ” ì–¸ì–´ í…ìŠ¤íŠ¸("ì™¼ìª½ìœ¼ë¡œ", "ìœ„ë¡œ")ë¥¼ ìë™ ë¼ë²¨ë§.
    2.  **Human-in-the-loop**: í…”ë ˆì˜¤í¼ë ˆì´ì…˜ ì¤‘ ìš´ì˜ìê°€ ì˜ë„ì ìœ¼ë¡œ ê¶¤ì ì„ í‹€ê³ , ë‹¤ì‹œ ìˆ˜ì •í•˜ëŠ” ë°ì´í„°ë¥¼ ìˆ˜ì§‘.

### 4. í‰ê°€ ë©”íŠ¸ë¦­ (Metrics)
- **Correction Success Rate (CSR)**: í”¼ë“œë°± í›„ $N$ì´ˆ ì´ë‚´ì— ëª©í‘œ ê¶¤ì ìœ¼ë¡œ ë³µê·€í–ˆëŠ”ì§€ ë¹„ìœ¨.
- **Reaction Time**: ì–¸ì–´ ëª…ë ¹ ì…ë ¥ í›„ ê¶¤ì  ë³€í™”ê°€ ì‹œì‘ë˜ê¸°ê¹Œì§€ì˜ ì‹œê°„ (Latency).

---

## Task 2: Adverb-Conditioned Motion Control (ACMC)
### 1. ì •ì˜ (Definition)
ë‹¨ìˆœí•œ ëª©í‘œ ë‹¬ì„±ì„ ë„˜ì–´, **ë¶€ì‚¬(Adverb)**ê°€ ì§€ì‹œí•˜ëŠ” **ë™ì‘ì˜ ìŠ¤íƒ€ì¼(Style)ê³¼ ì†ì„±(Dynamics)**ì„ ë°˜ì˜í•˜ì—¬ ë¡œë´‡ì„ ì œì–´í•˜ëŠ” íƒœìŠ¤í¬ì…ë‹ˆë‹¤. (What + **How**)

### 2. ì£¼ìš” Adverb Classes
| Class | ë¬¼ë¦¬ì  ì˜ë¯¸ (Physical Mapping) | ì‚¬ìš© ì˜ˆì‹œ |
| :--- | :--- | :--- |
| **Carefully / Gently** | ì†ë„($v$) ê°ì†Œ, ê°€ì†ë„($a$) ì œí•œ, ê·¸ë¦¬í¼ í˜($F$) ìµœì†Œí™” | ê¹¨ì§€ê¸° ì‰¬ìš´ ë¬¼ì»µ, ë‘ë¶€ ì§‘ê¸° |
| **Quickly / Rush** | ì†ë„($v$) ì¦ê°€, ê°€ì†ë„($a$) í—ˆìš©ì¹˜ ìµœëŒ€, ë™ì‘ ê°„ì†Œí™” | ê¸´ê¸‰ ì •ì§€, ë˜ì§€ê¸° |
| **Steadily** | ì§„ë™(Jerk) ìµœì†Œí™”, ì†ëª© ê³ ì • | ë¬¼ì´ ê½‰ ì°¬ ì»µ ì˜®ê¸°ê¸° |

### 3. ì…/ì¶œë ¥ (Input/Output)
- **Input**: RGB Image + Instruction (e.g., "Pour the water **carefully**")
- **Output**: Action Token + **Style Token** (Stiffness, Max Velocity Limit ë“±ì˜ íŒŒë¼ë¯¸í„° ì œì–´)

### 4. êµ¬í˜„ ë° ë°ì´í„° ì „ëµ
- **Style Injection**: ê¸°ì¡´ ë°ì´í„°ì…‹ì˜ ê¶¤ì (Trajectory)ì„ ë¦¬ìƒ˜í”Œë§í•˜ì—¬ ì†ë„ë¥¼ ì¡°ì ˆí•˜ê±°ë‚˜, í•„í„°ë¥¼ ì ìš©í•´ ë¶€ë“œëŸ½ê²Œ ë§Œë“  í›„, í•´ë‹¹ ìŠ¤íƒ€ì¼ì— ë§ëŠ” í…ìŠ¤íŠ¸("Slowly", "Smoothly")ë¥¼ Augmentationí•˜ì—¬ í•™ìŠµ.
- **Contrastive Learning**: ë™ì¼í•œ Task(ì»µ ì§‘ê¸°)ë¥¼ ìˆ˜í–‰í•˜ì§€ë§Œ ì„œë¡œ ë‹¤ë¥¸ ìŠ¤íƒ€ì¼(ë¹ ë¦„ vs ëŠë¦¼)ì„ ê°€ì§„ ë¹„ë””ì˜¤ ìŒì„ í†µí•´ VLAê°€ ìŠ¤íƒ€ì¼ì˜ ì°¨ì´ë¥¼ í•™ìŠµí•˜ë„ë¡ ìœ ë„.


---


# Motion VLA Implementation Plan

ì•ì„œ ì œì•ˆëœ ë‘ ê°€ì§€ íƒœìŠ¤í¬(LGTC, ACMC)ë¥¼ êµ¬í˜„í•˜ê¸° ìœ„í•œ ë‹¨ê³„ë³„ ì‹¤í–‰ ê³„íšì…ë‹ˆë‹¤.

## Phase 1: ê¸°ë°˜ í™˜ê²½ êµ¬ì¶• (Weeks 1-2)
ê°€ì¥ ì‹œê¸‰í•œ ê²ƒì€ "ë°ì´í„° í™•ë³´"ì˜ ì–´ë ¤ì›€ì„ í•´ê²°í•˜ëŠ” ì‹œë®¬ë ˆì´ì…˜ í™˜ê²½ êµ¬ì¶•ì…ë‹ˆë‹¤.
- [ ] **Simulation Environment**:
    - **Isaac Lab (formerly Orbit)** ì¶”ì²œ: GPU ê°€ì† ê¸°ë°˜ìœ¼ë¡œ ëŒ€ëŸ‰ì˜ ê¶¤ì  ë°ì´í„° ìƒì„± ê°€ëŠ¥.
    - ëŒ€ì•ˆ: **Robomimic / PyBullet** (ê°€ë³ê³  ì„¤ì •ì´ ì‰¬ì›€, ì´ˆê¸° ê²€ì¦ìš©).
- [ ] **Data Generation Pipeline**:
    - "Standard Trajectory"ë¥¼ ìƒì„±í•˜ëŠ” Oracle Agent êµ¬í˜„.
    - ê¶¤ì ì— Random Noiseë¥¼ ì£¼ì…í•˜ê³ , ì´ë¥¼ ë‹¤ì‹œ ì›ë³µ(Recovery)í•˜ëŠ” ê³¼ì •ì„ ë…¹í™”í•˜ì—¬ **Correction Dataset** ìë™ ìƒì„±.

## Phase 2: ë² ì´ìŠ¤ ëª¨ë¸ ì„ ì • ë° íŒŒì´í”„ë¼ì¸ (Weeks 3-4)
- [ ] **Base Model ì„ ì •**: **OpenVLA (7B)**
    - ì´ìœ : ì˜¤í”ˆì†ŒìŠ¤ ì¤‘ ê°€ì¥ ì„±ëŠ¥ì´ ì¢‹ê³ (Standard SOTA), Llama 2 ê¸°ë°˜ì´ë¼ ì–¸ì–´ ì´í•´ë„ê°€ ë†’ìŒ -> "Adverb" ì´í•´ì— ìœ ë¦¬.
    - ê²½ëŸ‰í™” í•„ìš” ì‹œ: **Octo-Small** ê³ ë ¤.
- [ ] **Fine-tuning Setup**:
    - **LoRA (Low-Rank Adaptation)** ì„¤ì •: VRAM íš¨ìœ¨ì„±ì„ ìœ„í•´ ì „ì²´ íŒŒë¼ë¯¸í„°ê°€ ì•„ë‹Œ LoRA íŠœë‹ ì‚¬ìš©.
    - **Action Head ìˆ˜ì •**: ê¸°ì¡´ Discrete Token Head ëŒ€ì‹ , ì—°ì†ì ì¸ ê°’ì„ ì˜ˆì¸¡í•˜ê±°ë‚˜ Style Tokenì„ ì¶”ê°€ë¡œ ì˜ˆì¸¡í•˜ë„ë¡ Head êµ¬ì¡° ë³€ê²½ ì‹¤í—˜.

## Phase 3: Task êµ¬í˜„ ë° ì‹¤í—˜ (Weeks 5-8)

### Track A: Language-Guided Correction (Task 1)
1.  ê¸°ì¡´ OpenX ë°ì´í„°ì…‹ìœ¼ë¡œ Pre-training ëœ ëª¨ë¸ ë¡œë“œ.
2.  Phase 1ì—ì„œ ìƒì„±í•œ `(Noisy Traj + "Right", Corrected Traj)` ë°ì´í„°ì…‹ìœ¼ë¡œ LoRA Fine-tuning.
3.  Evaluation: ì‹œë®¬ë ˆì´í„°ì—ì„œ ë¡œë´‡ì„ ì›€ì§ì´ë‹¤ê°€ ì¤‘ê°„ì— ê°œì… ëª…ë ¹ì„ ë‚´ë ¸ì„ ë•Œ ê¶¤ì  ë³€í™” ì¸¡ì •.

### Track B: Adverb-Conditioned Control (Task 2)
1.  BridgeData V2 ë“± ê¸°ì¡´ ë°ì´í„°ë¥¼ **ì†ë„/ê°€ì†ë„ ê¸°ë°˜ í•„í„°ë§**í•˜ì—¬ `Slow`, `Fast`, `Jerky` ë“±ìœ¼ë¡œ ë¶„ë¥˜(Auto-labeling).
2.  Instructionì— í•´ë‹¹ ë¶€ì‚¬ë¥¼ ë¶™ì—¬ í•™ìŠµ ("Pick up coke" -> "Pick up coke **quickly**").
3.  Evaluation: ë™ì¼í•œ "Pick up" ëª…ë ¹ì— ëŒ€í•´ ë¶€ì‚¬ì— ë”°ë¼ ì†Œìš” ì‹œê°„ê³¼ ê°€ì†ë„ í”„ë¡œíŒŒì¼ì´ ë‹¬ë¼ì§€ëŠ”ì§€ í™•ì¸.

---

## ğŸš€ Immediate Action Items (Today)
ë‹¹ì¥ ì˜¤ëŠ˜(ë‚¨ì€ 1ì‹œê°„) ì‹¤í–‰í•  êµ¬ì²´ì ì¸ ì‘ì—…ì…ë‹ˆë‹¤.

1.  **Dependencies ì„¤ì¹˜**: `requirements.txt` ì‘ì„± ë° ì„¤ì¹˜ (PyTorch, Transformers, Accelerate ë“±).
2.  **í”„ë¡œì íŠ¸ êµ¬ì¡°í™”**: `src/motion_vla/` íŒ¨í‚¤ì§€ ìƒì„± ë° `model.py` (OpenVLA ë¡œë”© ì½”ë“œ) ê»ë°ê¸° ì‘ì„±.
3.  **ë°ì´í„° ìŠ¤í‚¤ë§ˆ ì •ì˜**: í•™ìŠµì— ì‚¬ìš©í•  ë°ì´í„°ì…‹ í¬ë§·(JSON/HDF5) ì„¤ê³„ (`docs/data_schema.md`).


---


# Motion VLA Data Schema

## HDF5 Structure
í•™ìŠµ íš¨ìœ¨ì„±ì„ ìœ„í•´ **HDF5** í¬ë§·ì„ ê¸°ë³¸ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤. (Robomimic / OpenX í˜¸í™˜ì„± ê³ ë ¤)

```text
dataset.hdf5
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ demo_0/
â”‚   â”‚   â”œâ”€â”€ obs/
â”‚   â”‚   â”‚   â”œâ”€â”€ agentview_rgb     (T, H, W, 3)  # uint8
â”‚   â”‚   â”‚   â”œâ”€â”€ eye_in_hand_rgb   (T, H, W, 3)  # uint8
â”‚   â”‚   â”‚   â”œâ”€â”€ joint_positions   (T, D)        # float32
â”‚   â”‚   â”‚   â””â”€â”€ ee_pose           (T, 7)        # float32 (pos + quat)
â”‚   â”‚   â”œâ”€â”€ actions/              (T, D)        # float32 (Next joint pos or delta)
â”‚   â”‚   â”œâ”€â”€ rewards/              (T,)
â”‚   â”‚   â”œâ”€â”€ dones/                (T,)
â”‚   â”‚   â””â”€â”€ language_instruction  (String Attribute)
â”‚   â”œâ”€â”€ demo_1/
â”‚   â””â”€â”€ ...
â””â”€â”€ mask/
    â”œâ”€â”€ train/                    (List of demo keys)
    â””â”€â”€ valid/                    (List of demo keys)
```

## Custom Attributes for Motion VLA
ì‹ ê·œ íƒœìŠ¤í¬ë¥¼ ìœ„í•´ ê° ë°ëª¨(Group)ì— ë‹¤ìŒ Attributeë‚˜ Datasetì´ ì¶”ê°€ë©ë‹ˆë‹¤.

1.  **`motion_style` (Attribute)**:
    - Type: `String`
    - Values: `"careful"`, `"fast"`, `"jerky"`, `"normal"`
    - Usage: Task 2 (Adverb Control) í•™ìŠµ ì‹œ Conditionìœ¼ë¡œ ì‚¬ìš©.

2.  **`correction_label` (Dataset)**:
    - Type: `(T,) int8`
    - Values: `0` (Normal), `1` (Correction Start), `2` (Correction End)
    - Usage: Task 1 (Trajectory Correction)ì—ì„œ ìˆ˜ì • êµ¬ê°„ì„ ì‹ë³„í•˜ê¸° ìœ„í•¨.
